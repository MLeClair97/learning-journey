{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e6c4ff",
   "metadata": {},
   "source": [
    "## Day 6: Merging and Joining Data\n",
    "Goal: Master SQL JOINs in pandas\n",
    "\n",
    "First, doing some basic joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b92ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data setup\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4],\n",
    "    'customer_name': ['Alice Corp', 'Bob Inc', 'Charlie Ltd', 'Delta Co'],\n",
    "    'region': ['North', 'South', 'East', 'West']\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [101, 102, 103, 104, 105],\n",
    "    'customer_id': [1, 1, 2, 3, 5],  # Note: customer_id 5 doesn't exist in customers\n",
    "    'total_amount': [1000, 1500, 2000, 750, 3000],\n",
    "    'order_date': ['2023-01-15', '2023-02-20', '2023-01-30', '2023-03-10', '2023-02-05']\n",
    "})\n",
    "\n",
    "# SQL: SELECT * FROM customers c INNER JOIN orders o ON c.customer_id = o.customer_id\n",
    "inner_join = pd.merge(customers, orders, on='customer_id', how='inner')\n",
    "print(\"Inner Join Result:\")\n",
    "print(inner_join)\n",
    "\n",
    "# SQL: SELECT * FROM customers c LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
    "left_join = pd.merge(customers, orders, on='customer_id', how='left')\n",
    "\n",
    "print(\"\\nLeft Join Result:\")\n",
    "print(left_join)    \n",
    "\n",
    "# SQL: SELECT * FROM customers c RIGHT JOIN orders o ON c.customer_id = o.customer_id\n",
    "right_join = pd.merge(customers, orders, on='customer_id', how='right')\n",
    "print(\"\\nRight Join Result:\")\n",
    "print(right_join)\n",
    "\n",
    "# SQL: SELECT * FROM customers c FULL OUTER JOIN orders o ON c.customer_id = o.customer_id\n",
    "outer_join = pd.merge(customers, orders, on='customer_id', how='outer')\n",
    "print(\"\\nOuter Join Result:\")\n",
    "print(outer_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36219ab4",
   "metadata": {},
   "source": [
    "These are pretty straightforward.  Merge, on, how is logical.\n",
    "\n",
    "*Note*:  Today I learned about \\n next line formatting character that will give a space between the results instead of them being right next to each other.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94525463",
   "metadata": {},
   "source": [
    "Next, Advanced Joining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5dab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining on multiple columns with matching column names\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data for multiple column join\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4],\n",
    "    'customer_name': ['Alice Corp', 'Bob Inc', 'Charlie Ltd', 'Delta Co'],\n",
    "    'location': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n",
    "    'region': ['North', 'South', 'East', 'West']\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [101, 102, 103, 104, 105],\n",
    "    'customer_id': [1, 1, 2, 3, 5],  \n",
    "    'total_amount': [1000, 1500, 2000, 750, 3000],\n",
    "    'order_date': ['2023-01-15', '2023-02-20', '2023-01-30', '2023-03-10', '2023-02-05'],\n",
    "    'location': ['New York', 'New York', 'Los Angeles', 'Chicago', 'Miami']\n",
    "})\n",
    "\n",
    "\n",
    "# SQL: JOIN ON table1.col1 = table2.col1 AND table1.col2 = table2.col2 \n",
    "pd.merge(customers, orders, on=['customer_id', 'location'])\n",
    "print(\"Join on multiple columns Result:\")\n",
    "print(pd.merge(customers, orders, on=['customer_id', 'location']))\n",
    "\n",
    "# Joining with suffixes for duplicate column names\n",
    "print(\"\\nJoin with suffixes for duplicate column names:\")\n",
    "# SQL: SELECT * FROM customers c INNER JOIN orders o ON c.customer_id = o.customer_id\n",
    "print(pd.merge(customers, orders, on='customer_id', suffixes=('_left', '_right')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47515663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining on multiple columns with different column names\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data for multiple column join\n",
    "customers = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'customer_name': ['Alice Corp', 'Bob Inc', 'Charlie Ltd', 'Delta Co'],\n",
    "    'location': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n",
    "    'region': ['North', 'South', 'East', 'West']\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [101, 102, 103, 104, 105],\n",
    "    'customer_id': [1, 1, 2, 3, 5],  \n",
    "    'total_amount': [1000, 1500, 2000, 750, 3000],\n",
    "    'order_date': ['2023-01-15', '2023-02-20', '2023-01-30', '2023-03-10', '2023-02-05'],\n",
    "    'location': ['New York', 'New York', 'Los Angeles', 'Chicago', 'Miami']\n",
    "})\n",
    "\n",
    "# SQL: JOIN ON orders.customer_id = customers.id\n",
    "print(\"\\nJoin on different column names Result:\")\n",
    "print(pd.merge(orders, customers, left_on='customer_id', right_on='id'))\n",
    "\n",
    "# Joining on multiple columns with different column names and suffixes\n",
    "print(\"\\nJoin on multiple columns with different names and suffixes Result:\")\n",
    "print(pd.merge(orders, customers, left_on=['customer_id', 'location'], right_on=['id', 'location'], suffixes=('_order', '_customer')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2294c496",
   "metadata": {},
   "source": [
    "This is interesting because SQL doesn't have this issue... \n",
    "In pandas, when you merge two DataFrames that have columns with the same name (other than the one you're joining on), those columns would conflict in the resulting DataFrame. To resolve this, you can use the suffixes parameter in pd.merge(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining with suffixes for duplicate column names\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data for multiple column join\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4],\n",
    "    'customer_name': ['Alice Corp', 'Bob Inc', 'Charlie Ltd', 'Delta Co'],\n",
    "    'location': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n",
    "    'region': ['North', 'South', 'East', 'West']\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [101, 102, 103, 104, 105],\n",
    "    'customer_id': [1, 1, 2, 3, 5],  \n",
    "    'total_amount': [1000, 1500, 2000, 750, 3000],\n",
    "    'order_date': ['2023-01-15', '2023-02-20', '2023-01-30', '2023-03-10', '2023-02-05'],\n",
    "    'location': ['New York', 'New York', 'Los Angeles', 'Chicago', 'Miami']\n",
    "})\n",
    "\n",
    "# SQL: SELECT * FROM customers c INNER JOIN orders o ON c.customer_id = o.customer_id\n",
    "print(\"\\nJoin with suffixes for duplicate column names:\")\n",
    "print(pd.merge(customers, orders, on='customer_id', suffixes=('_left', '_right')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64bd71a",
   "metadata": {},
   "source": [
    "Suffix Example Breakdown:\n",
    "\n",
    "`customers` and `orders` are being joined on the `customer_id` column.\n",
    "\n",
    "If both DataFrames have a column like `name` or `address`, they would conflict.\n",
    "\n",
    "With `suffixes=('_left', '_right')`, you’d see them renamed like:\n",
    "\n",
    "- `name_left` → from the `customers` DataFrame (left side)\n",
    "- `name_right` → from the `orders` DataFrame (right side)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16276b0c",
   "metadata": {},
   "source": [
    "____________\n",
    "This pandas code performs an **index-based join** between two DataFrames, similar to a SQL join that uses row numbers or positions rather than specific column values.\n",
    "How it works\n",
    "The `.join()` method merges DataFrames based on their index values (row labels). It's essentially saying \"combine rows that have the same index position.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5339e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index-based joining (like SQL using row numbers)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create sample DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'score': [85, 90, 78]\n",
    "}, index=[0, 1, 2])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'name': ['Marketing', 'Engineering', 'Sales'],\n",
    "    'budget': [50000, 80000, 60000]\n",
    "}, index=[0, 1, 2])\n",
    "\n",
    "print(df1.join(df2, lsuffix='_left', rsuffix='_right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0207460",
   "metadata": {},
   "source": [
    "Key characteristics of index joins\n",
    "- *Default behavior*: Left join (keeps all rows from df1)\n",
    "- *Index alignment*: Rows are matched by their index values\n",
    "- *Automatic suffixing*: Only applies to columns with duplicate names\n",
    "- *Efficient*: Generally faster than `merge()` for index-based operations\n",
    "This is particularly useful when you have DataFrames that are naturally aligned by their row positions and you want to combine their columns horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fde1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating dataframes (UNION equivalent) (vertical concatenation)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create sample DataFrames (with some overlapping data)\n",
    "df1 = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'department': ['Engineering', 'Sales', 'Marketing'],\n",
    "    'salary': [75000, 65000, 70000]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'name': ['Bob', 'Diana', 'Charlie'],  # Bob and Charlie are duplicates\n",
    "    'department': ['Sales', 'Engineering', 'Marketing'],\n",
    "    'salary': [65000, 80000, 70000]\n",
    "})\n",
    "\n",
    "# SQL: SELECT * FROM table1 UNION ALL SELECT * FROM table2\n",
    "# Preserves duplicates: Like UNION ALL, keeps duplicate rows (unlike UNION)\n",
    "# Column alignment: Matches columns by name automatically\n",
    "print(\"\\nConcatenating DataFrames (with duplicates):\")\n",
    "print(pd.concat([df1, df2], ignore_index=True))\n",
    "# Index handling: ignore_index=True creates clean sequential numbering\n",
    "\n",
    "\n",
    "# SQL: SELECT * FROM table1 UNION SELECT * FROM table2 (removes duplicates)\n",
    "print(\"\\nConcatenating DataFrames (removing duplicates):\")\n",
    "print(pd.concat([df1, df2]).drop_duplicates())  \n",
    "\n",
    "# Removes duplicates: Unlike UNION ALL, eliminates identical rows\n",
    "# Preserves original indices: Notice indices 0, 1, 2, 4 (index 3 was dropped as duplicate)\n",
    "# Row-wise comparison: Considers entire rows when identifying duplicates\n",
    "# Maintains order: Generally keeps the first occurrence of duplicate rows\n",
    "# This is useful when combining datasets where you want to eliminate redundant records and create a unique set of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb66b8f",
   "metadata": {},
   "source": [
    "--PRACTICE--\n",
    "Challenge: use Seaborn data to practice some of these SQL rewrite concepts.  AI generated tip table split below to get me started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b7a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the tips dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Create related tables for practice\n",
    "customers = tips[['total_bill', 'tip', 'sex', 'smoker']].drop_duplicates().reset_index(drop=True)\n",
    "customers['customer_id'] = range(len(customers))\n",
    "\n",
    "meals = tips[['day', 'time', 'size']].drop_duplicates().reset_index(drop=True)\n",
    "meals['meal_id'] = range(len(meals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ea2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "### Practice Filtering with Seaborn's tips dataset\n",
    "\n",
    "# Load the tips dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Create related tables for practice\n",
    "customers = tips[['total_bill', 'tip', 'sex', 'smoker']].drop_duplicates().reset_index(drop=True)\n",
    "customers['customer_id'] = range(len(customers))\n",
    "\n",
    "meals = tips[['day', 'time', 'size']].drop_duplicates().reset_index(drop=True)\n",
    "meals['meal_id'] = range(len(meals))\n",
    "\n",
    "    ## Find all tips over $5\n",
    "    # SELECT * FROM tips WHERE tip > 5;\n",
    "print(\"\\nTips over $5:\")\n",
    "print(customers[customers['tip'] > 5])\n",
    "    # The inner customers['tip']>5 Boolean condition that checks each row of the tip column to see if the value is greater than 5.\n",
    "    # It returns a Series of True/False values. \n",
    "    # Then pass the Boolean Series from the previous step to customers[...], so only the rows where the condition is True will be included\n",
    "    # Then it prints the filtered DataFrame rows where the boolean condition is True.\n",
    "\n",
    "    # SELECT * FROM tips WHERE day IN ('Sat', 'Sun');\n",
    "print(\"\\nTips on Saturday or Sunday:\")\n",
    "print(meals[meals['day'].isin(['Sat', 'Sun'])])\n",
    "\n",
    "    # SELECT * FROM tips WHERE size > 2;\n",
    "print(\"\\nMeals with size greater than 2:\")  \n",
    "print(meals[meals['size'] > 2])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "### Practice Aggregation\n",
    "\n",
    "# Load the tips dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Create related tables for practice\n",
    "customers = tips[['total_bill', 'tip', 'sex', 'smoker']].drop_duplicates().reset_index(drop=True)\n",
    "customers['customer_id'] = range(len(customers))\n",
    "\n",
    "meals = tips[['day', 'time', 'size']].drop_duplicates().reset_index(drop=True)\n",
    "meals['meal_id'] = range(len(meals))\n",
    "\n",
    "# Average tip by day SQL: SELECT day, AVG(tip) as avg_tip FROM tips GROUP BY day;\n",
    "\n",
    "avg_tip_by_day = tips.groupby('day', observed=True)['tip'].mean()\n",
    "print(\"\\nAverage tip by day:\")\n",
    "print(avg_tip_by_day)\n",
    "\n",
    "# Total bills by smoker status SQL: SELECT smoker, SUM(total_bill) as total_revenue FROM tips GROUP BY smoker;\n",
    "print(\"\\nTotal bills by smoker status:\" )\n",
    "total_bills_by_smoker = customers.groupby('smoker', observed=True)['total_bill'].sum()\n",
    "print(total_bills_by_smoker)\n",
    "\n",
    "# Average tip percentage by day and time SQL: SELECT day, time, AVG(tip/total_bill * 100) as avg_tip_pct FROM tips GROUP BY day, time ORDER BY avg_tip_pct DESC;\n",
    "tips['tip_pct'] = tips['tip'] / tips['total_bill'] * 100\n",
    "avg_tip_pct_by_day_time = tips.groupby(['day', 'time'], observed=True)['tip_pct'].mean().reset_index()\n",
    "# Rename the columns for clarity\n",
    "avg_tip_pct_by_day_time.columns = ['day', 'time', 'avg_tip_pct'] \n",
    "# The original column name tip_pct refers to individual tip percentages, but after grouping and taking the mean, it represents the average tip percentage. So avg_tip_pct is more descriptive and accurate.\n",
    "print(\"\\nAverage tip percentage by day and time:\")\n",
    "# Sort by day ascending, then time descending\n",
    "print(avg_tip_pct_by_day_time.sort_values(by=['day','time'], ascending=[True,False]))\n",
    "\n",
    "# Party size statistics SQL: SELECT size, COUNT(*) as frequency, AVG(total_bill) as avg_bill FROM tips GROUP BY size HAVING COUNT(*) > 5;\n",
    "party_size_stats = tips.groupby('size', observed=True).agg(\n",
    "    frequency=('size', 'size'),  # Count of occurrences\n",
    "    avg_bill=('total_bill', 'mean')  # Average total bill\n",
    ").reset_index()\n",
    "print(\"\\nParty size statistics (size, frequency, avg_bill):\")\n",
    "print(party_size_stats[party_size_stats['frequency'] > 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297238b5",
   "metadata": {},
   "source": [
    "*Note* Due to message about panda change, used `observed=True` to avoid future warnings\n",
    "This will group the tips dataset by the 'day' column and calculate the average tip for each day.\n",
    "The observed=True parameter ensures that only the days present in the dataset are included in the result.\n",
    " - First version: tips.groupby('day')['tip'].mean()\n",
    " - Updated version: tips.groupby('day', observed=True)['tip'].mean()\n",
    "\n",
    "Now for advanced query stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783041ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Window Functions \n",
    "# Rank customers by tip amount within each day\n",
    "# SQL: SELECT *, RANK() OVER (PARTITION BY day ORDER BY tip DESC) as tip_rank FROM tips;\n",
    "ranked_tips = tips.assign(\n",
    "    tip_rank=tips.groupby('day')['tip'].rank(method='first', ascending=False)\n",
    ").sort_values(by=['day', 'tip_rank'])\n",
    "print(\"\\nRanked tips by day:\")\n",
    "print(ranked_tips[['day', 'tip', 'tip_rank']])\n",
    "\n",
    "# Running total of tips by day\n",
    "# SQL: SELECT day, tip, SUM(tip) OVER (PARTITION BY day ORDER BY total_bill) as running_total FROM tips;\n",
    "# First sort to match SQL's ORDER BY inside the window\n",
    "sorted_tips = tips.sort_values(by=['day', 'total_bill'])\n",
    "# Then compute running total using groupby and cumsum\n",
    "running_total_tips = sorted_tips.assign(running_total=sorted_tips.groupby('day')['tip'].cumsum())\n",
    "# Finally, display selected columns\n",
    "print(\"\\nRunning total of tips by day:\")\n",
    "print(running_total_tips[['day', 'tip', 'running_total']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subqueries\n",
    "# Find above-average tippers SQl: SELECT * FROM tips WHERE tip > (SELECT AVG(tip) FROM tips);\n",
    "above_average_tippers = tips[tips['tip'] > tips['tip'].mean()]\n",
    "print(\"\\nAbove-average tippers:\")\n",
    "print(above_average_tippers)\n",
    "\n",
    "# -- Tip percentage categories SQL: SELECT *, CASE \n",
    "# WHEN tip/total_bill < 0.15 THEN 'Below Average'  WHEN tip/total_bill < 0.20 THEN 'Average' ELSE 'Generous'\n",
    "# END as tipper_type FROM tips;\n",
    "    \n",
    "    ## using `pd.cut` to categorize tip percentages\n",
    "# Step 1: Add tip_percent to the dataframe\n",
    "tips_with_percent = tips.assign(tip_percent = tips['tip'] / tips['total_bill'])\n",
    "# Step 2: Add tipper_type based on tip_percent \n",
    "tip_percentage = tips_with_percent.assign(\n",
    "    tipper_type = pd.cut(\n",
    "        tips_with_percent['tip_percent'],\n",
    "        bins=[-float('inf'), 0.15, 0.20, float('inf')],\n",
    "        labels=['Below Average', 'Average', 'Generous']))\n",
    "print(\"\\nTip percentage categories:\")\n",
    "print(tip_percentage[['total_bill', 'tip', 'tip_percent', 'tipper_type']])\n",
    "    \n",
    "    ## using `np.where()` to categorize tip percentages\n",
    "# Step 1: Add tip_percent to the dataframe  \n",
    "tips_with_percent = tips.assign(tip_percent = tips['tip'] / tips['total_bill'])\n",
    "# Step 2: Add tipper_type based on tip_percent using np.where\n",
    "import numpy as np\n",
    "tips_with_type = tips_with_percent.assign(\n",
    "    tipper_type = np.where(\n",
    "        tips_with_percent['tip_percent'] < 0.15, 'Below Average',\n",
    "        np.where(tips_with_percent['tip_percent'] < 0.20, 'Average', 'Generous')))   \n",
    "print(\"\\nTip percentage categories using np.where:\")\n",
    "print(tips_with_type[['total_bill', 'tip', 'tip_percent', 'tipper_type']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5118987",
   "metadata": {},
   "source": [
    "### 🔍 How `np.where()` Works Here\n",
    "\n",
    "Think of it like regular Python logic:\n",
    "\n",
    "```python\n",
    "if tip_percent > 0.20:\n",
    "    'Generous'\n",
    "elif tip_percent > 0.15:\n",
    "    'Average'\n",
    "else:\n",
    "    'Below Average'\n",
    "# You're nesting np.where() to express multiple conditions inline, similar to if-elif-else.\n",
    "\n",
    "| Use Case                    | Best Tool     | Why                                              |\n",
    "| --------------------------- | ------------- | ------------------------------------------------ |\n",
    "| Even, numeric bins          | `pd.cut()`    | Cleaner, automatic bin labeling                  |\n",
    "| Custom conditions           | `np.where()`  | Full control over logic                          |\n",
    "| Complex/multiple conditions | `np.select()` | Scalable alternative to many nested `np.where()` |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
