{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86720a5",
   "metadata": {},
   "source": [
    "#### Final Project: Create a Database Analytics Dashboard\n",
    "\n",
    "Challenge = Create a script that can connect to all three database types and generate unified reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9920229",
   "metadata": {},
   "source": [
    "#### Workflow:\n",
    "\n",
    "- Explore: Run the Database Explorer to see what tables and columns exists in each\n",
    "- Customize: Modify queries in the Manual Query Builder to match the actual schema\n",
    "- Execute: Run unified reports with custom queries\n",
    "\n",
    "Database Explorer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ccdbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class DatabaseExplorer:\n",
    "    \"\"\"Simple tool to explore database schemas and tables\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.connections = {}\n",
    "    \n",
    "    def add_sqlite_connection(self, name, db_path):\n",
    "        \"\"\"Add SQLite database\"\"\"\n",
    "        self.connections[name] = {\n",
    "            'type': 'sqlite',\n",
    "            'path': db_path\n",
    "        }\n",
    "        print(f\"Added SQLite connection: {name}\")\n",
    "    \n",
    "    def add_postgresql_connection(self, name, connection_string):\n",
    "        \"\"\"Add PostgreSQL database\"\"\"\n",
    "        self.connections[name] = {\n",
    "            'type': 'postgresql',\n",
    "            'connection_string': connection_string\n",
    "        }\n",
    "        print(f\"Added PostgreSQL connection: {name}\")\n",
    "    \n",
    "    def add_sqlserver_connection(self, name, connection_url):\n",
    "        \"\"\"Add SQL Server connection using full SQLAlchemy URL\"\"\"\n",
    "        self.connections[name] = {\n",
    "            'type': 'sqlserver',\n",
    "            'connection_url': connection_url,\n",
    "            'connection': None\n",
    "        }\n",
    "        print(f\"Added SQL Server connection: {name}\")\n",
    "    \n",
    "    def explore_sqlite(self, db_path):\n",
    "        \"\"\"Explore SQLite database structure\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(db_path)\n",
    "            \n",
    "            # Get all tables\n",
    "            tables_query = \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "            tables_df = pd.read_sql_query(tables_query, conn)\n",
    "            \n",
    "            print(\"TABLES:\")\n",
    "            for table in tables_df['name']:\n",
    "                print(f\"  - {table}\")\n",
    "                \n",
    "                # Get columns for each table\n",
    "                columns_query = f\"PRAGMA table_info({table})\"\n",
    "                columns_df = pd.read_sql_query(columns_query, conn)\n",
    "                \n",
    "                print(\"    COLUMNS:\")\n",
    "                for _, row in columns_df.iterrows():\n",
    "                    print(f\"      {row['name']} ({row['type']})\")\n",
    "                \n",
    "                # Show sample data\n",
    "                try:\n",
    "                    sample_query = f\"SELECT * FROM {table} LIMIT 3\"\n",
    "                    sample_df = pd.read_sql_query(sample_query, conn)\n",
    "                    print(f\"    SAMPLE DATA ({len(sample_df)} rows):\")\n",
    "                    if not sample_df.empty:\n",
    "                        print(f\"      {list(sample_df.columns)}\")\n",
    "                        for i, row in sample_df.iterrows():\n",
    "                            print(f\"      {list(row.values)}\")\n",
    "                    print()\n",
    "                except Exception as e:\n",
    "                    print(f\"      Error getting sample data: {e}\\n\")\n",
    "            \n",
    "            conn.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error exploring SQLite database: {e}\")\n",
    "    \n",
    "    def explore_postgresql(self, connection_string):\n",
    "        \"\"\"Explore PostgreSQL database structure\"\"\"\n",
    "        try:\n",
    "            engine = create_engine(connection_string)\n",
    "            \n",
    "            # Get all tables\n",
    "            tables_query = \"\"\"\n",
    "            SELECT table_name \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema = 'public'\n",
    "            ORDER BY table_name\n",
    "            \"\"\"\n",
    "            tables_df = pd.read_sql_query(text(tables_query), engine)\n",
    "            \n",
    "            print(\"TABLES:\")\n",
    "            for table in tables_df['table_name']:\n",
    "                print(f\"  - {table}\")\n",
    "                \n",
    "                # Get columns for each table\n",
    "                columns_query = f\"\"\"\n",
    "                SELECT column_name, data_type, is_nullable\n",
    "                FROM information_schema.columns \n",
    "                WHERE table_name = '{table}'\n",
    "                ORDER BY ordinal_position\n",
    "                \"\"\"\n",
    "                columns_df = pd.read_sql_query(text(columns_query), engine)\n",
    "                \n",
    "                print(\"    COLUMNS:\")\n",
    "                for _, row in columns_df.iterrows():\n",
    "                    nullable = \"NULL\" if row['is_nullable'] == 'YES' else \"NOT NULL\"\n",
    "                    print(f\"      {row['column_name']} ({row['data_type']}, {nullable})\")\n",
    "                \n",
    "                # Show sample data\n",
    "                try:\n",
    "                    sample_query = f\"SELECT * FROM {table} LIMIT 3\"\n",
    "                    sample_df = pd.read_sql_query(text(sample_query), engine)\n",
    "                    print(f\"    SAMPLE DATA ({len(sample_df)} rows):\")\n",
    "                    if not sample_df.empty:\n",
    "                        print(f\"      {list(sample_df.columns)}\")\n",
    "                        for i, row in sample_df.iterrows():\n",
    "                            print(f\"      {list(row.values)}\")\n",
    "                    print()\n",
    "                except Exception as e:\n",
    "                    print(f\"      Error getting sample data: {e}\\n\")\n",
    "            \n",
    "            engine.dispose()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error exploring PostgreSQL database: {e}\")\n",
    "    \n",
    "    def explore_sqlserver(self, conn_info):\n",
    "        \"\"\"Explore SQL Server database structure with proper schema support\"\"\"\n",
    "        try:\n",
    "            # Check if a full connection URL is provided\n",
    "            if 'connection_url' in conn_info:\n",
    "                connection_string = conn_info['connection_url']\n",
    "            else:\n",
    "                # Build from parts (legacy style)\n",
    "                server = conn_info['server']\n",
    "                database = conn_info['database']\n",
    "                trusted = conn_info.get('trusted', True)\n",
    "                trusted_str = 'yes' if trusted else 'no'\n",
    "\n",
    "                connection_string = (\n",
    "                f\"mssql+pyodbc://@{server}/{database}\"\n",
    "                f\"?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection={trusted_str}\"\n",
    "                )\n",
    "\n",
    "            engine = create_engine(connection_string)\n",
    "\n",
    "            # Get all tables with schema information\n",
    "            tables_query = \"\"\"\n",
    "                SELECT TABLE_SCHEMA, TABLE_NAME,\n",
    "                       TABLE_SCHEMA + '.' + TABLE_NAME as FULL_TABLE_NAME\n",
    "                FROM INFORMATION_SCHEMA.TABLES \n",
    "                WHERE TABLE_TYPE = 'BASE TABLE'\n",
    "                ORDER BY TABLE_SCHEMA, TABLE_NAME\n",
    "            \"\"\"\n",
    "            tables_df = pd.read_sql_query(text(tables_query), engine)\n",
    "            \n",
    "            print(\"TABLES:\")\n",
    "            current_schema = None\n",
    "            \n",
    "            for _, table_row in tables_df.iterrows():\n",
    "                schema = table_row['TABLE_SCHEMA']\n",
    "                table = table_row['TABLE_NAME']\n",
    "                full_name = table_row['FULL_TABLE_NAME']\n",
    "                \n",
    "                # Print schema header when it changes\n",
    "                if current_schema != schema:\n",
    "                    if current_schema is not None:\n",
    "                        print()  # Add spacing between schemas\n",
    "                    print(f\"  SCHEMA: {schema}\")\n",
    "                    current_schema = schema\n",
    "                \n",
    "                print(f\"    - {full_name}\")\n",
    "                \n",
    "                # Get columns for each table\n",
    "                columns_query = f\"\"\"\n",
    "                    SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE\n",
    "                    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "                    WHERE TABLE_SCHEMA = '{schema}' AND TABLE_NAME = '{table}'\n",
    "                    ORDER BY ORDINAL_POSITION\n",
    "                \"\"\"\n",
    "                columns_df = pd.read_sql_query(text(columns_query), engine)\n",
    "                \n",
    "                print(\"      COLUMNS:\")\n",
    "                for _, row in columns_df.iterrows():\n",
    "                    nullable = \"NULL\" if row['IS_NULLABLE'] == 'YES' else \"NOT NULL\"\n",
    "                    print(f\"        {row['COLUMN_NAME']} ({row['DATA_TYPE']}, {nullable})\")\n",
    "                \n",
    "                # Show sample data using full schema.table name\n",
    "                try:\n",
    "                    sample_query = f\"SELECT TOP 3 * FROM [{schema}].[{table}]\"\n",
    "                    sample_df = pd.read_sql_query(text(sample_query), engine)\n",
    "                    print(f\"      SAMPLE DATA ({len(sample_df)} rows):\")\n",
    "                    if not sample_df.empty:\n",
    "                        print(f\"        {list(sample_df.columns)}\")\n",
    "                        for i, row in sample_df.iterrows():\n",
    "                            # Convert values to string and truncate if too long\n",
    "                            values = []\n",
    "                            for val in row.values:\n",
    "                                str_val = str(val)\n",
    "                                if len(str_val) > 50:\n",
    "                                    str_val = str_val[:47] + \"...\"\n",
    "                                values.append(str_val)\n",
    "                            print(f\"        {values}\")\n",
    "                    print()\n",
    "                except Exception as e:\n",
    "                    print(f\"      Error getting sample data: {str(e)[:100]}...\\n\")\n",
    "            \n",
    "            engine.dispose()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error exploring SQL Server database: {e}\")\n",
    "    \n",
    "    def explore_all_databases(self):\n",
    "        \"\"\"Explore all connected databases\"\"\"\n",
    "        for name, conn_info in self.connections.items():\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"EXPLORING DATABASE: {name.upper()}\")\n",
    "            print(f\"TYPE: {conn_info['type'].upper()}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            if conn_info['type'] == 'sqlite':\n",
    "                self.explore_sqlite(conn_info['path'])\n",
    "            elif conn_info['type'] == 'postgresql':\n",
    "                self.explore_postgresql(conn_info['connection_string'])\n",
    "            elif conn_info['type'] == 'sqlserver':\n",
    "                self.explore_sqlserver(conn_info) \n",
    "\n",
    "# Usage Example\n",
    "explorer = DatabaseExplorer()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Add all your database connections\n",
    "# SQLite connection (uncomment if you have the file)\n",
    "# explorer.add_sqlite_connection('local_db', 'business_data.db')\n",
    "\n",
    "# PostgreSQL connection (uncomment if you have PostgreSQL)\n",
    "# postgres_url = os.getenv('DATABASE_URL')\n",
    "# if postgres_url:\n",
    "#     explorer.add_postgresql_connection('pg_db', postgres_url)\n",
    "\n",
    "# SQL Server connection\n",
    "sqlserver_url = os.getenv('SQLSERVER_URL')\n",
    "if sqlserver_url:\n",
    "    explorer.add_sqlserver_connection('AdventureWorks2022', sqlserver_url)\n",
    "\n",
    "# Explore all databases\n",
    "print(\"EXPLORING ALL CONFIGURED DATABASES:\")\n",
    "print(\"=\"*60)\n",
    "explorer.explore_all_databases()\n",
    "\n",
    "# You can also explore individual databases\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INDIVIDUAL DATABASE EXPLORATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Explore just SQL Server database directly\n",
    "print(\"\\nExploring SQL Server AdventureWorks2022 database:\")\n",
    "sqlserver_url_direct = \"mssql+pyodbc://localhost\\\\SQLEXPRESS/AdventureWorks2022?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\"\n",
    "explorer.add_sqlserver_connection('AdventureWorks2022', sqlserver_url_direct)\n",
    "explorer.explore_sqlserver(explorer.connections['AdventureWorks2022'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSTRUCTIONS:\")\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… Database Explorer is working!\")\n",
    "print(\"ðŸ“‹ Tables are organized by schema (Person, Sales, Production, etc.)\")\n",
    "print(\"ðŸ” Sample data is shown for each table\") \n",
    "print(\"ðŸ’¡ Use schema.table format in queries (e.g., Person.Address)\")\n",
    "print(\"ðŸš€ Ready for the next step: Manual Query Builder!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bde79a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ MULTI-DATABASE QUERY BUILDER\n",
      "============================================================\n",
      "Setting up database connections...\n",
      "âœ… SQL Server connection 'adventureworks' added successfully\n",
      "âœ… PostgreSQL connection 'postgres_db' added successfully\n",
      "âœ… SQLite connection 'sqlite_business_data_db' added successfully\n",
      "\n",
      "============================================================\n",
      "AVAILABLE DATABASE CONNECTIONS:\n",
      "==================================================\n",
      "ðŸŸ¢ adventureworks (SQLSERVER)\n",
      "ðŸŸ¢ postgres_db (POSTGRESQL)\n",
      "ðŸŸ¢ sqlite_business_data_db (SQLITE)\n",
      "\n",
      "============================================================\n",
      "EXAMPLE USAGE:\n",
      "============================================================\n",
      "\n",
      "# List all connections\n",
      "query_builder.list_connections()\n",
      "\n",
      "# Get database info\n",
      "query_builder.get_database_info('adventureworks')\n",
      "\n",
      "# Quick table query\n",
      "query_builder.quick_table_query('adventureworks', 'dbo.AWBuildVersion')\n",
      "\n",
      "# Custom SQL query\n",
      "query = '''\n",
      "SELECT TABLE_SCHEMA, COUNT(*) as table_count \n",
      "FROM INFORMATION_SCHEMA.TABLES \n",
      "WHERE TABLE_TYPE = 'BASE TABLE'\n",
      "GROUP BY TABLE_SCHEMA\n",
      "'''\n",
      "query_builder.execute_query('adventureworks', query)\n",
      "\n",
      "# Query with export\n",
      "query_builder.execute_query('adventureworks', \n",
      "    'SELECT TOP 100 * FROM dbo.DatabaseLog ORDER BY PostTime DESC',\n",
      "    export_to='database_log.csv')\n",
      "\n",
      "# Complex query example for AdventureWorks\n",
      "complex_query = '''\n",
      "SELECT \n",
      "    p.Name as ProductName,\n",
      "    pc.Name as CategoryName,\n",
      "    p.ListPrice,\n",
      "    p.Color\n",
      "FROM Production.Product p\n",
      "JOIN Production.ProductSubcategory ps ON p.ProductSubcategoryID = ps.ProductSubcategoryID  \n",
      "JOIN Production.ProductCategory pc ON ps.ProductCategoryID = pc.ProductCategoryID\n",
      "WHERE p.ListPrice > 0\n",
      "ORDER BY p.ListPrice DESC\n",
      "'''\n",
      "query_builder.execute_query('adventureworks', complex_query, limit=20)\n",
      "\n",
      "# Show query history\n",
      "query_builder.show_query_history()\n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ’¡ TIPS:\n",
      "============================================================\n",
      "â€¢ Use schema.table format for SQL Server (e.g., 'Person.Address')\n",
      "â€¢ Queries automatically get LIMIT/TOP clauses for safety\n",
      "â€¢ Export results to CSV or Excel with export_to parameter\n",
      "â€¢ Use quick_table_query() for simple SELECT statements\n",
      "â€¢ Check query_history to see past executions\n",
      "â€¢ SQL Server tables: Person, Sales, Production, HumanResources schemas\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MultiDatabaseQueryBuilder:\n",
    "    \"\"\"Advanced tool for running custom queries across multiple databases\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.connections = {}\n",
    "        self.query_history = []\n",
    "        load_dotenv()\n",
    "        \n",
    "    def add_sqlite_connection(self, name, db_path):\n",
    "        \"\"\"Add SQLite database connection\"\"\"\n",
    "        try:\n",
    "            # Test connection\n",
    "            conn = sqlite3.connect(db_path)\n",
    "            conn.close()\n",
    "            \n",
    "            self.connections[name] = {\n",
    "                'type': 'sqlite',\n",
    "                'path': db_path,\n",
    "                'status': 'connected'\n",
    "            }\n",
    "            print(f\"âœ… SQLite connection '{name}' added successfully\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to add SQLite connection '{name}': {e}\")\n",
    "            return False\n",
    "    \n",
    "    def add_postgresql_connection(self, name, connection_string):\n",
    "        \"\"\"Add PostgreSQL database connection\"\"\"\n",
    "        try:\n",
    "            # Test connection\n",
    "            engine = create_engine(connection_string)\n",
    "            with engine.connect():\n",
    "                pass\n",
    "            engine.dispose()\n",
    "            \n",
    "            self.connections[name] = {\n",
    "                'type': 'postgresql',\n",
    "                'connection_string': connection_string,\n",
    "                'status': 'connected'\n",
    "            }\n",
    "            print(f\"âœ… PostgreSQL connection '{name}' added successfully\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to add PostgreSQL connection '{name}': {e}\")\n",
    "            return False\n",
    "    \n",
    "    def add_sqlserver_connection(self, name, connection_url):\n",
    "        \"\"\"Add SQL Server database connection\"\"\"\n",
    "        try:\n",
    "            # Test connection\n",
    "            engine = create_engine(connection_url)\n",
    "            with engine.connect():\n",
    "                pass\n",
    "            engine.dispose()\n",
    "            \n",
    "            self.connections[name] = {\n",
    "                'type': 'sqlserver',\n",
    "                'connection_url': connection_url,\n",
    "                'status': 'connected'\n",
    "            }\n",
    "            print(f\"âœ… SQL Server connection '{name}' added successfully\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to add SQL Server connection '{name}': {e}\")\n",
    "            return False\n",
    "    \n",
    "    def list_connections(self):\n",
    "        \"\"\"List all available database connections\"\"\"\n",
    "        if not self.connections:\n",
    "            print(\"No database connections configured.\")\n",
    "            return\n",
    "        \n",
    "        print(\"AVAILABLE DATABASE CONNECTIONS:\")\n",
    "        print(\"=\" * 50)\n",
    "        for name, info in self.connections.items():\n",
    "            status_icon = \"ðŸŸ¢\" if info['status'] == 'connected' else \"ðŸ”´\"\n",
    "            print(f\"{status_icon} {name} ({info['type'].upper()})\")\n",
    "    \n",
    "    def execute_query(self, database_name, query, limit=None, export_to=None):\n",
    "        \"\"\"Execute a custom query on specified database\"\"\"\n",
    "        \n",
    "        if database_name not in self.connections:\n",
    "            print(f\"âŒ Database '{database_name}' not found. Available: {list(self.connections.keys())}\")\n",
    "            return None\n",
    "        \n",
    "        conn_info = self.connections[database_name]\n",
    "        \n",
    "        try:\n",
    "            print(f\"ðŸ” Executing query on {database_name} ({conn_info['type'].upper()})...\")\n",
    "            print(f\"ðŸ“ Query: {query[:100]}...\" if len(query) > 100 else f\"ðŸ“ Query: {query}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # Execute based on database type\n",
    "            if conn_info['type'] == 'sqlite':\n",
    "                result_df = self._execute_sqlite_query(conn_info, query, limit)\n",
    "            elif conn_info['type'] == 'postgresql':\n",
    "                result_df = self._execute_postgresql_query(conn_info, query, limit)\n",
    "            elif conn_info['type'] == 'sqlserver':\n",
    "                result_df = self._execute_sqlserver_query(conn_info, query, limit)\n",
    "            else:\n",
    "                print(f\"âŒ Unsupported database type: {conn_info['type']}\")\n",
    "                return None\n",
    "            \n",
    "            # Log query to history\n",
    "            self.query_history.append({\n",
    "                'timestamp': datetime.now(),\n",
    "                'database': database_name,\n",
    "                'query': query,\n",
    "                'rows_returned': len(result_df) if result_df is not None else 0\n",
    "            })\n",
    "            \n",
    "            # Display results\n",
    "            if result_df is not None and not result_df.empty:\n",
    "                print(f\"âœ… Query executed successfully! Returned {len(result_df)} rows\")\n",
    "                print(f\"ðŸ“Š Columns: {list(result_df.columns)}\")\n",
    "                print(\"\\nðŸ“‹ RESULTS:\")\n",
    "                print(\"=\" * 80)\n",
    "                \n",
    "                # Display with better formatting\n",
    "                pd.set_option('display.max_columns', None)\n",
    "                pd.set_option('display.width', None)\n",
    "                pd.set_option('display.max_colwidth', 50)\n",
    "                print(result_df.to_string(index=False))\n",
    "                \n",
    "                # Export if requested\n",
    "                if export_to:\n",
    "                    self._export_results(result_df, export_to)\n",
    "                \n",
    "                return result_df\n",
    "            else:\n",
    "                print(\"âœ… Query executed successfully but returned no results\")\n",
    "                return pd.DataFrame()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Query execution failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _execute_sqlite_query(self, conn_info, query, limit):\n",
    "        \"\"\"Execute query on SQLite database\"\"\"\n",
    "        conn = sqlite3.connect(conn_info['path'])\n",
    "        \n",
    "        # Add LIMIT if specified and not already in query\n",
    "        if limit and 'LIMIT' not in query.upper():\n",
    "            query = f\"{query.rstrip(';')} LIMIT {limit}\"\n",
    "        \n",
    "        result_df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        return result_df\n",
    "    \n",
    "    def _execute_postgresql_query(self, conn_info, query, limit):\n",
    "        \"\"\"Execute query on PostgreSQL database\"\"\"\n",
    "        engine = create_engine(conn_info['connection_string'])\n",
    "        \n",
    "        # Add LIMIT if specified and not already in query\n",
    "        if limit and 'LIMIT' not in query.upper():\n",
    "            query = f\"{query.rstrip(';')} LIMIT {limit}\"\n",
    "        \n",
    "        result_df = pd.read_sql_query(text(query), engine)\n",
    "        engine.dispose()\n",
    "        return result_df\n",
    "    \n",
    "    def _execute_sqlserver_query(self, conn_info, query, limit):\n",
    "        \"\"\"Execute query on SQL Server database\"\"\"\n",
    "        engine = create_engine(conn_info['connection_url'])\n",
    "        \n",
    "        # Add TOP if specified and not already in query\n",
    "        if limit and 'TOP' not in query.upper():\n",
    "            # Insert TOP clause after SELECT\n",
    "            query_upper = query.upper()\n",
    "            select_pos = query_upper.find('SELECT')\n",
    "            if select_pos != -1:\n",
    "                insert_pos = select_pos + 6  # After \"SELECT\"\n",
    "                query = query[:insert_pos] + f\" TOP {limit}\" + query[insert_pos:]\n",
    "        \n",
    "        result_df = pd.read_sql_query(text(query), engine)\n",
    "        engine.dispose()\n",
    "        return result_df\n",
    "    \n",
    "    def _export_results(self, df, export_path):\n",
    "        \"\"\"Export query results to file\"\"\"\n",
    "        try:\n",
    "            if export_path.endswith('.csv'):\n",
    "                df.to_csv(export_path, index=False)\n",
    "                print(f\"ðŸ’¾ Results exported to {export_path}\")\n",
    "            elif export_path.endswith(('.xlsx', '.xls')):\n",
    "                df.to_excel(export_path, index=False)\n",
    "                print(f\"ðŸ’¾ Results exported to {export_path}\")\n",
    "            else:\n",
    "                print(f\"âŒ Unsupported export format. Use .csv or .xlsx\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Export failed: {e}\")\n",
    "    \n",
    "    def quick_table_query(self, database_name, table_name, columns=\"*\", where_clause=\"\", limit=10):\n",
    "        \"\"\"Generate and execute a quick SELECT query\"\"\"\n",
    "        \n",
    "        if where_clause and not where_clause.upper().strip().startswith('WHERE'):\n",
    "            where_clause = f\"WHERE {where_clause}\"\n",
    "        \n",
    "        query = f\"SELECT {columns} FROM {table_name} {where_clause}\".strip()\n",
    "        \n",
    "        return self.execute_query(database_name, query, limit=limit)\n",
    "    \n",
    "    def show_query_history(self):\n",
    "        \"\"\"Display query execution history\"\"\"\n",
    "        if not self.query_history:\n",
    "            print(\"No query history available.\")\n",
    "            return\n",
    "        \n",
    "        print(\"QUERY HISTORY:\")\n",
    "        print(\"=\" * 80)\n",
    "        for i, entry in enumerate(self.query_history[-10:], 1):  # Show last 10\n",
    "            timestamp = entry['timestamp'].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            query_preview = entry['query'][:50] + \"...\" if len(entry['query']) > 50 else entry['query']\n",
    "            print(f\"{i}. [{timestamp}] {entry['database']} - {entry['rows_returned']} rows\")\n",
    "            print(f\"   Query: {query_preview}\")\n",
    "            print()\n",
    "    \n",
    "    def get_database_info(self, database_name):\n",
    "        \"\"\"Get quick info about a database\"\"\"\n",
    "        if database_name not in self.connections:\n",
    "            print(f\"âŒ Database '{database_name}' not found\")\n",
    "            return\n",
    "        \n",
    "        conn_info = self.connections[database_name]\n",
    "        \n",
    "        try:\n",
    "            if conn_info['type'] == 'sqlite':\n",
    "                query = \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "            elif conn_info['type'] == 'postgresql':\n",
    "                query = \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\"\n",
    "            elif conn_info['type'] == 'sqlserver':\n",
    "                query = \"\"\"SELECT TABLE_SCHEMA + '.' + TABLE_NAME as full_name \n",
    "                          FROM INFORMATION_SCHEMA.TABLES \n",
    "                          WHERE TABLE_TYPE = 'BASE TABLE' \n",
    "                          ORDER BY TABLE_SCHEMA, TABLE_NAME\"\"\"\n",
    "            \n",
    "            tables_df = self.execute_query(database_name, query, limit=50)\n",
    "            \n",
    "            if tables_df is not None:\n",
    "                print(f\"\\nðŸ“Š Database '{database_name}' has {len(tables_df)} tables\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error getting database info: {e}\")\n",
    "\n",
    "# Initialize Query Builder\n",
    "print(\"ðŸš€ MULTI-DATABASE QUERY BUILDER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query_builder = MultiDatabaseQueryBuilder()\n",
    "\n",
    "# Auto-setup connections from environment variables\n",
    "print(\"Setting up database connections...\")\n",
    "\n",
    "# SQL Server connection (primary)\n",
    "sqlserver_url = os.getenv('SQLSERVER_URL')\n",
    "if sqlserver_url:\n",
    "    query_builder.add_sqlserver_connection('adventureworks', sqlserver_url)\n",
    "else:\n",
    "    # Fallback to direct connection\n",
    "    sqlserver_url = \"mssql+pyodbc://localhost\\\\SQLEXPRESS/AdventureWorks2022?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\"\n",
    "    query_builder.add_sqlserver_connection('adventureworks', sqlserver_url)\n",
    "\n",
    "# PostgreSQL connection (if available)\n",
    "postgres_url = os.getenv('DATABASE_URL')\n",
    "if postgres_url:\n",
    "    query_builder.add_postgresql_connection('postgres_db', postgres_url)\n",
    "\n",
    "# SQLite connection (if file exists)\n",
    "sqlite_files = ['business_data.db', 'sample.db', 'data.db']\n",
    "for db_file in sqlite_files:\n",
    "    if os.path.exists(db_file):\n",
    "        query_builder.add_sqlite_connection(f'sqlite_{db_file.replace(\".\", \"_\")}', db_file)\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "query_builder.list_connections()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXAMPLE USAGE:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "# List all connections\n",
    "query_builder.list_connections()\n",
    "\n",
    "# Get database info\n",
    "query_builder.get_database_info('adventureworks')\n",
    "\n",
    "# Quick table query\n",
    "query_builder.quick_table_query('adventureworks', 'dbo.AWBuildVersion')\n",
    "\n",
    "# Custom SQL query\n",
    "query = '''\n",
    "SELECT TABLE_SCHEMA, COUNT(*) as table_count \n",
    "FROM INFORMATION_SCHEMA.TABLES \n",
    "WHERE TABLE_TYPE = 'BASE TABLE'\n",
    "GROUP BY TABLE_SCHEMA\n",
    "'''\n",
    "query_builder.execute_query('adventureworks', query)\n",
    "\n",
    "# Query with export\n",
    "query_builder.execute_query('adventureworks', \n",
    "    'SELECT TOP 100 * FROM dbo.DatabaseLog ORDER BY PostTime DESC',\n",
    "    export_to='database_log.csv')\n",
    "\n",
    "# Complex query example for AdventureWorks\n",
    "complex_query = '''\n",
    "SELECT \n",
    "    p.Name as ProductName,\n",
    "    pc.Name as CategoryName,\n",
    "    p.ListPrice,\n",
    "    p.Color\n",
    "FROM Production.Product p\n",
    "JOIN Production.ProductSubcategory ps ON p.ProductSubcategoryID = ps.ProductSubcategoryID  \n",
    "JOIN Production.ProductCategory pc ON ps.ProductCategoryID = pc.ProductCategoryID\n",
    "WHERE p.ListPrice > 0\n",
    "ORDER BY p.ListPrice DESC\n",
    "'''\n",
    "query_builder.execute_query('adventureworks', complex_query, limit=20)\n",
    "\n",
    "# Show query history\n",
    "query_builder.show_query_history()\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ’¡ TIPS:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"â€¢ Use schema.table format for SQL Server (e.g., 'Person.Address')\")\n",
    "print(\"â€¢ Queries automatically get LIMIT/TOP clauses for safety\")\n",
    "print(\"â€¢ Export results to CSV or Excel with export_to parameter\")\n",
    "print(\"â€¢ Use quick_table_query() for simple SELECT statements\")\n",
    "print(\"â€¢ Check query_history to see past executions\")\n",
    "print(\"â€¢ SQL Server tables: Person, Sales, Production, HumanResources schemas\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
