{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86720a5",
   "metadata": {},
   "source": [
    "#### Final Project: Create a Database Analytics Dashboard\n",
    "\n",
    "Challenge = Create a script that can connect to all three database types and generate unified reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9920229",
   "metadata": {},
   "source": [
    "#### Workflow:\n",
    "\n",
    "- Explore: Run the Database Explorer to see what tables and columns exists in each\n",
    "- Customize: Modify queries in the Manual Query Builder to match the actual schema\n",
    "- Execute: Run unified reports with custom queries\n",
    "\n",
    "Database Explorer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ccdbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class DatabaseExplorer:\n",
    "    \"\"\"Simple tool to explore database schemas and tables\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.connections = {}\n",
    "    \n",
    "    def add_sqlite_connection(self, name, db_path):\n",
    "        \"\"\"Add SQLite database\"\"\"\n",
    "        self.connections[name] = {\n",
    "            'type': 'sqlite',\n",
    "            'path': db_path\n",
    "        }\n",
    "        print(f\"Added SQLite connection: {name}\")\n",
    "    \n",
    "    def add_postgresql_connection(self, name, connection_string):\n",
    "        \"\"\"Add PostgreSQL database\"\"\"\n",
    "        self.connections[name] = {\n",
    "            'type': 'postgresql',\n",
    "            'connection_string': connection_string\n",
    "        }\n",
    "        print(f\"Added PostgreSQL connection: {name}\")\n",
    "    \n",
    "    def add_sqlserver_connection(self, name, connection_url):\n",
    "        \"\"\"Add SQL Server connection using full SQLAlchemy URL\"\"\"\n",
    "        self.connections[name] = {\n",
    "            'type': 'sqlserver',\n",
    "            'connection_url': connection_url,\n",
    "            'connection': None\n",
    "        }\n",
    "        print(f\"Added SQL Server connection: {name}\")\n",
    "    \n",
    "    def explore_sqlite(self, db_path):\n",
    "        \"\"\"Explore SQLite database structure\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(db_path)\n",
    "            \n",
    "            # Get all tables\n",
    "            tables_query = \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "            tables_df = pd.read_sql_query(tables_query, conn)\n",
    "            \n",
    "            print(\"TABLES:\")\n",
    "            for table in tables_df['name']:\n",
    "                print(f\"  - {table}\")\n",
    "                \n",
    "                # Get columns for each table\n",
    "                columns_query = f\"PRAGMA table_info({table})\"\n",
    "                columns_df = pd.read_sql_query(columns_query, conn)\n",
    "                \n",
    "                print(\"    COLUMNS:\")\n",
    "                for _, row in columns_df.iterrows():\n",
    "                    print(f\"      {row['name']} ({row['type']})\")\n",
    "                \n",
    "                # Show sample data\n",
    "                try:\n",
    "                    sample_query = f\"SELECT * FROM {table} LIMIT 3\"\n",
    "                    sample_df = pd.read_sql_query(sample_query, conn)\n",
    "                    print(f\"    SAMPLE DATA ({len(sample_df)} rows):\")\n",
    "                    if not sample_df.empty:\n",
    "                        print(f\"      {list(sample_df.columns)}\")\n",
    "                        for i, row in sample_df.iterrows():\n",
    "                            print(f\"      {list(row.values)}\")\n",
    "                    print()\n",
    "                except Exception as e:\n",
    "                    print(f\"      Error getting sample data: {e}\\n\")\n",
    "            \n",
    "            conn.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error exploring SQLite database: {e}\")\n",
    "    \n",
    "    def explore_postgresql(self, connection_string):\n",
    "        \"\"\"Explore PostgreSQL database structure\"\"\"\n",
    "        try:\n",
    "            engine = create_engine(connection_string)\n",
    "            \n",
    "            # Get all tables\n",
    "            tables_query = \"\"\"\n",
    "            SELECT table_name \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema = 'public'\n",
    "            ORDER BY table_name\n",
    "            \"\"\"\n",
    "            tables_df = pd.read_sql_query(text(tables_query), engine)\n",
    "            \n",
    "            print(\"TABLES:\")\n",
    "            for table in tables_df['table_name']:\n",
    "                print(f\"  - {table}\")\n",
    "                \n",
    "                # Get columns for each table\n",
    "                columns_query = f\"\"\"\n",
    "                SELECT column_name, data_type, is_nullable\n",
    "                FROM information_schema.columns \n",
    "                WHERE table_name = '{table}'\n",
    "                ORDER BY ordinal_position\n",
    "                \"\"\"\n",
    "                columns_df = pd.read_sql_query(text(columns_query), engine)\n",
    "                \n",
    "                print(\"    COLUMNS:\")\n",
    "                for _, row in columns_df.iterrows():\n",
    "                    nullable = \"NULL\" if row['is_nullable'] == 'YES' else \"NOT NULL\"\n",
    "                    print(f\"      {row['column_name']} ({row['data_type']}, {nullable})\")\n",
    "                \n",
    "                # Show sample data\n",
    "                try:\n",
    "                    sample_query = f\"SELECT * FROM {table} LIMIT 3\"\n",
    "                    sample_df = pd.read_sql_query(text(sample_query), engine)\n",
    "                    print(f\"    SAMPLE DATA ({len(sample_df)} rows):\")\n",
    "                    if not sample_df.empty:\n",
    "                        print(f\"      {list(sample_df.columns)}\")\n",
    "                        for i, row in sample_df.iterrows():\n",
    "                            print(f\"      {list(row.values)}\")\n",
    "                    print()\n",
    "                except Exception as e:\n",
    "                    print(f\"      Error getting sample data: {e}\\n\")\n",
    "            \n",
    "            engine.dispose()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error exploring PostgreSQL database: {e}\")\n",
    "    \n",
    "    def explore_sqlserver(self, conn_info):\n",
    "        \"\"\"Explore SQL Server database structure with proper schema support\"\"\"\n",
    "        try:\n",
    "            # Check if a full connection URL is provided\n",
    "            if 'connection_url' in conn_info:\n",
    "                connection_string = conn_info['connection_url']\n",
    "            else:\n",
    "                # Build from parts (legacy style)\n",
    "                server = conn_info['server']\n",
    "                database = conn_info['database']\n",
    "                trusted = conn_info.get('trusted', True)\n",
    "                trusted_str = 'yes' if trusted else 'no'\n",
    "\n",
    "                connection_string = (\n",
    "                f\"mssql+pyodbc://@{server}/{database}\"\n",
    "                f\"?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection={trusted_str}\"\n",
    "                )\n",
    "\n",
    "            engine = create_engine(connection_string)\n",
    "\n",
    "            # Get all tables with schema information\n",
    "            tables_query = \"\"\"\n",
    "                SELECT TABLE_SCHEMA, TABLE_NAME,\n",
    "                       TABLE_SCHEMA + '.' + TABLE_NAME as FULL_TABLE_NAME\n",
    "                FROM INFORMATION_SCHEMA.TABLES \n",
    "                WHERE TABLE_TYPE = 'BASE TABLE'\n",
    "                ORDER BY TABLE_SCHEMA, TABLE_NAME\n",
    "            \"\"\"\n",
    "            tables_df = pd.read_sql_query(text(tables_query), engine)\n",
    "            \n",
    "            print(\"TABLES:\")\n",
    "            current_schema = None\n",
    "            \n",
    "            for _, table_row in tables_df.iterrows():\n",
    "                schema = table_row['TABLE_SCHEMA']\n",
    "                table = table_row['TABLE_NAME']\n",
    "                full_name = table_row['FULL_TABLE_NAME']\n",
    "                \n",
    "                # Print schema header when it changes\n",
    "                if current_schema != schema:\n",
    "                    if current_schema is not None:\n",
    "                        print()  # Add spacing between schemas\n",
    "                    print(f\"  SCHEMA: {schema}\")\n",
    "                    current_schema = schema\n",
    "                \n",
    "                print(f\"    - {full_name}\")\n",
    "                \n",
    "                # Get columns for each table\n",
    "                columns_query = f\"\"\"\n",
    "                    SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE\n",
    "                    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "                    WHERE TABLE_SCHEMA = '{schema}' AND TABLE_NAME = '{table}'\n",
    "                    ORDER BY ORDINAL_POSITION\n",
    "                \"\"\"\n",
    "                columns_df = pd.read_sql_query(text(columns_query), engine)\n",
    "                \n",
    "                print(\"      COLUMNS:\")\n",
    "                for _, row in columns_df.iterrows():\n",
    "                    nullable = \"NULL\" if row['IS_NULLABLE'] == 'YES' else \"NOT NULL\"\n",
    "                    print(f\"        {row['COLUMN_NAME']} ({row['DATA_TYPE']}, {nullable})\")\n",
    "                \n",
    "                # Show sample data using full schema.table name\n",
    "                try:\n",
    "                    sample_query = f\"SELECT TOP 3 * FROM [{schema}].[{table}]\"\n",
    "                    sample_df = pd.read_sql_query(text(sample_query), engine)\n",
    "                    print(f\"      SAMPLE DATA ({len(sample_df)} rows):\")\n",
    "                    if not sample_df.empty:\n",
    "                        print(f\"        {list(sample_df.columns)}\")\n",
    "                        for i, row in sample_df.iterrows():\n",
    "                            # Convert values to string and truncate if too long\n",
    "                            values = []\n",
    "                            for val in row.values:\n",
    "                                str_val = str(val)\n",
    "                                if len(str_val) > 50:\n",
    "                                    str_val = str_val[:47] + \"...\"\n",
    "                                values.append(str_val)\n",
    "                            print(f\"        {values}\")\n",
    "                    print()\n",
    "                except Exception as e:\n",
    "                    print(f\"      Error getting sample data: {str(e)[:100]}...\\n\")\n",
    "            \n",
    "            engine.dispose()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error exploring SQL Server database: {e}\")\n",
    "    \n",
    "    def explore_all_databases(self):\n",
    "        \"\"\"Explore all connected databases\"\"\"\n",
    "        for name, conn_info in self.connections.items():\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"EXPLORING DATABASE: {name.upper()}\")\n",
    "            print(f\"TYPE: {conn_info['type'].upper()}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            if conn_info['type'] == 'sqlite':\n",
    "                self.explore_sqlite(conn_info['path'])\n",
    "            elif conn_info['type'] == 'postgresql':\n",
    "                self.explore_postgresql(conn_info['connection_string'])\n",
    "            elif conn_info['type'] == 'sqlserver':\n",
    "                self.explore_sqlserver(conn_info) \n",
    "\n",
    "# Usage Example\n",
    "explorer = DatabaseExplorer()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Add all your database connections\n",
    "# SQLite connection (uncomment if you have the file)\n",
    "# explorer.add_sqlite_connection('local_db', 'business_data.db')\n",
    "\n",
    "# PostgreSQL connection (uncomment if you have PostgreSQL)\n",
    "# postgres_url = os.getenv('DATABASE_URL')\n",
    "# if postgres_url:\n",
    "#     explorer.add_postgresql_connection('pg_db', postgres_url)\n",
    "\n",
    "# SQL Server connection\n",
    "sqlserver_url = os.getenv('SQLSERVER_URL')\n",
    "if sqlserver_url:\n",
    "    explorer.add_sqlserver_connection('AdventureWorks2022', sqlserver_url)\n",
    "\n",
    "# Explore all databases\n",
    "print(\"EXPLORING ALL CONFIGURED DATABASES:\")\n",
    "print(\"=\"*60)\n",
    "explorer.explore_all_databases()\n",
    "\n",
    "# You can also explore individual databases\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INDIVIDUAL DATABASE EXPLORATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Explore just SQL Server database directly\n",
    "print(\"\\nExploring SQL Server AdventureWorks2022 database:\")\n",
    "sqlserver_url_direct = \"mssql+pyodbc://localhost\\\\SQLEXPRESS/AdventureWorks2022?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\"\n",
    "explorer.add_sqlserver_connection('AdventureWorks2022', sqlserver_url_direct)\n",
    "explorer.explore_sqlserver(explorer.connections['AdventureWorks2022'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSTRUCTIONS:\")\n",
    "print(\"=\"*60)\n",
    "print(\"✅ Database Explorer is working!\")\n",
    "print(\"📋 Tables are organized by schema (Person, Sales, Production, etc.)\")\n",
    "print(\"🔍 Sample data is shown for each table\") \n",
    "print(\"💡 Use schema.table format in queries (e.g., Person.Address)\")\n",
    "print(\"🚀 Ready for the next step: Manual Query Builder!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bde79a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 MULTI-DATABASE QUERY BUILDER\n",
      "============================================================\n",
      "Setting up database connections...\n",
      "✅ SQL Server connection 'adventureworks' added successfully\n",
      "✅ PostgreSQL connection 'postgres_db' added successfully\n",
      "✅ SQLite connection 'sqlite_business_data_db' added successfully\n",
      "\n",
      "============================================================\n",
      "AVAILABLE DATABASE CONNECTIONS:\n",
      "==================================================\n",
      "🟢 adventureworks (SQLSERVER)\n",
      "🟢 postgres_db (POSTGRESQL)\n",
      "🟢 sqlite_business_data_db (SQLITE)\n",
      "\n",
      "============================================================\n",
      "EXAMPLE USAGE:\n",
      "============================================================\n",
      "\n",
      "# List all connections\n",
      "query_builder.list_connections()\n",
      "\n",
      "# Get database info\n",
      "query_builder.get_database_info('adventureworks')\n",
      "\n",
      "# Quick table query\n",
      "query_builder.quick_table_query('adventureworks', 'dbo.AWBuildVersion')\n",
      "\n",
      "# Custom SQL query\n",
      "query = '''\n",
      "SELECT TABLE_SCHEMA, COUNT(*) as table_count \n",
      "FROM INFORMATION_SCHEMA.TABLES \n",
      "WHERE TABLE_TYPE = 'BASE TABLE'\n",
      "GROUP BY TABLE_SCHEMA\n",
      "'''\n",
      "query_builder.execute_query('adventureworks', query)\n",
      "\n",
      "# Query with export\n",
      "query_builder.execute_query('adventureworks', \n",
      "    'SELECT TOP 100 * FROM dbo.DatabaseLog ORDER BY PostTime DESC',\n",
      "    export_to='database_log.csv')\n",
      "\n",
      "# Complex query example for AdventureWorks\n",
      "complex_query = '''\n",
      "SELECT \n",
      "    p.Name as ProductName,\n",
      "    pc.Name as CategoryName,\n",
      "    p.ListPrice,\n",
      "    p.Color\n",
      "FROM Production.Product p\n",
      "JOIN Production.ProductSubcategory ps ON p.ProductSubcategoryID = ps.ProductSubcategoryID  \n",
      "JOIN Production.ProductCategory pc ON ps.ProductCategoryID = pc.ProductCategoryID\n",
      "WHERE p.ListPrice > 0\n",
      "ORDER BY p.ListPrice DESC\n",
      "'''\n",
      "query_builder.execute_query('adventureworks', complex_query, limit=20)\n",
      "\n",
      "# Show query history\n",
      "query_builder.show_query_history()\n",
      "\n",
      "\n",
      "============================================================\n",
      "💡 TIPS:\n",
      "============================================================\n",
      "• Use schema.table format for SQL Server (e.g., 'Person.Address')\n",
      "• Queries automatically get LIMIT/TOP clauses for safety\n",
      "• Export results to CSV or Excel with export_to parameter\n",
      "• Use quick_table_query() for simple SELECT statements\n",
      "• Check query_history to see past executions\n",
      "• SQL Server tables: Person, Sales, Production, HumanResources schemas\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MultiDatabaseQueryBuilder:\n",
    "    \"\"\"Advanced tool for running custom queries across multiple databases\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.connections = {}\n",
    "        self.query_history = []\n",
    "        load_dotenv()\n",
    "        \n",
    "    def add_sqlite_connection(self, name, db_path):\n",
    "        \"\"\"Add SQLite database connection\"\"\"\n",
    "        try:\n",
    "            # Test connection\n",
    "            conn = sqlite3.connect(db_path)\n",
    "            conn.close()\n",
    "            \n",
    "            self.connections[name] = {\n",
    "                'type': 'sqlite',\n",
    "                'path': db_path,\n",
    "                'status': 'connected'\n",
    "            }\n",
    "            print(f\"✅ SQLite connection '{name}' added successfully\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to add SQLite connection '{name}': {e}\")\n",
    "            return False\n",
    "    \n",
    "    def add_postgresql_connection(self, name, connection_string):\n",
    "        \"\"\"Add PostgreSQL database connection\"\"\"\n",
    "        try:\n",
    "            # Test connection\n",
    "            engine = create_engine(connection_string)\n",
    "            with engine.connect():\n",
    "                pass\n",
    "            engine.dispose()\n",
    "            \n",
    "            self.connections[name] = {\n",
    "                'type': 'postgresql',\n",
    "                'connection_string': connection_string,\n",
    "                'status': 'connected'\n",
    "            }\n",
    "            print(f\"✅ PostgreSQL connection '{name}' added successfully\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to add PostgreSQL connection '{name}': {e}\")\n",
    "            return False\n",
    "    \n",
    "    def add_sqlserver_connection(self, name, connection_url):\n",
    "        \"\"\"Add SQL Server database connection\"\"\"\n",
    "        try:\n",
    "            # Test connection\n",
    "            engine = create_engine(connection_url)\n",
    "            with engine.connect():\n",
    "                pass\n",
    "            engine.dispose()\n",
    "            \n",
    "            self.connections[name] = {\n",
    "                'type': 'sqlserver',\n",
    "                'connection_url': connection_url,\n",
    "                'status': 'connected'\n",
    "            }\n",
    "            print(f\"✅ SQL Server connection '{name}' added successfully\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to add SQL Server connection '{name}': {e}\")\n",
    "            return False\n",
    "    \n",
    "    def list_connections(self):\n",
    "        \"\"\"List all available database connections\"\"\"\n",
    "        if not self.connections:\n",
    "            print(\"No database connections configured.\")\n",
    "            return\n",
    "        \n",
    "        print(\"AVAILABLE DATABASE CONNECTIONS:\")\n",
    "        print(\"=\" * 50)\n",
    "        for name, info in self.connections.items():\n",
    "            status_icon = \"🟢\" if info['status'] == 'connected' else \"🔴\"\n",
    "            print(f\"{status_icon} {name} ({info['type'].upper()})\")\n",
    "    \n",
    "    def execute_query(self, database_name, query, limit=None, export_to=None):\n",
    "        \"\"\"Execute a custom query on specified database\"\"\"\n",
    "        \n",
    "        if database_name not in self.connections:\n",
    "            print(f\"❌ Database '{database_name}' not found. Available: {list(self.connections.keys())}\")\n",
    "            return None\n",
    "        \n",
    "        conn_info = self.connections[database_name]\n",
    "        \n",
    "        try:\n",
    "            print(f\"🔍 Executing query on {database_name} ({conn_info['type'].upper()})...\")\n",
    "            print(f\"📝 Query: {query[:100]}...\" if len(query) > 100 else f\"📝 Query: {query}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # Execute based on database type\n",
    "            if conn_info['type'] == 'sqlite':\n",
    "                result_df = self._execute_sqlite_query(conn_info, query, limit)\n",
    "            elif conn_info['type'] == 'postgresql':\n",
    "                result_df = self._execute_postgresql_query(conn_info, query, limit)\n",
    "            elif conn_info['type'] == 'sqlserver':\n",
    "                result_df = self._execute_sqlserver_query(conn_info, query, limit)\n",
    "            else:\n",
    "                print(f\"❌ Unsupported database type: {conn_info['type']}\")\n",
    "                return None\n",
    "            \n",
    "            # Log query to history\n",
    "            self.query_history.append({\n",
    "                'timestamp': datetime.now(),\n",
    "                'database': database_name,\n",
    "                'query': query,\n",
    "                'rows_returned': len(result_df) if result_df is not None else 0\n",
    "            })\n",
    "            \n",
    "            # Display results\n",
    "            if result_df is not None and not result_df.empty:\n",
    "                print(f\"✅ Query executed successfully! Returned {len(result_df)} rows\")\n",
    "                print(f\"📊 Columns: {list(result_df.columns)}\")\n",
    "                print(\"\\n📋 RESULTS:\")\n",
    "                print(\"=\" * 80)\n",
    "                \n",
    "                # Display with better formatting\n",
    "                pd.set_option('display.max_columns', None)\n",
    "                pd.set_option('display.width', None)\n",
    "                pd.set_option('display.max_colwidth', 50)\n",
    "                print(result_df.to_string(index=False))\n",
    "                \n",
    "                # Export if requested\n",
    "                if export_to:\n",
    "                    self._export_results(result_df, export_to)\n",
    "                \n",
    "                return result_df\n",
    "            else:\n",
    "                print(\"✅ Query executed successfully but returned no results\")\n",
    "                return pd.DataFrame()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Query execution failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _execute_sqlite_query(self, conn_info, query, limit):\n",
    "        \"\"\"Execute query on SQLite database\"\"\"\n",
    "        conn = sqlite3.connect(conn_info['path'])\n",
    "        \n",
    "        # Add LIMIT if specified and not already in query\n",
    "        if limit and 'LIMIT' not in query.upper():\n",
    "            query = f\"{query.rstrip(';')} LIMIT {limit}\"\n",
    "        \n",
    "        result_df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        return result_df\n",
    "    \n",
    "    def _execute_postgresql_query(self, conn_info, query, limit):\n",
    "        \"\"\"Execute query on PostgreSQL database\"\"\"\n",
    "        engine = create_engine(conn_info['connection_string'])\n",
    "        \n",
    "        # Add LIMIT if specified and not already in query\n",
    "        if limit and 'LIMIT' not in query.upper():\n",
    "            query = f\"{query.rstrip(';')} LIMIT {limit}\"\n",
    "        \n",
    "        result_df = pd.read_sql_query(text(query), engine)\n",
    "        engine.dispose()\n",
    "        return result_df\n",
    "    \n",
    "    def _execute_sqlserver_query(self, conn_info, query, limit):\n",
    "        \"\"\"Execute query on SQL Server database\"\"\"\n",
    "        engine = create_engine(conn_info['connection_url'])\n",
    "        \n",
    "        # Add TOP if specified and not already in query\n",
    "        if limit and 'TOP' not in query.upper():\n",
    "            # Insert TOP clause after SELECT\n",
    "            query_upper = query.upper()\n",
    "            select_pos = query_upper.find('SELECT')\n",
    "            if select_pos != -1:\n",
    "                insert_pos = select_pos + 6  # After \"SELECT\"\n",
    "                query = query[:insert_pos] + f\" TOP {limit}\" + query[insert_pos:]\n",
    "        \n",
    "        result_df = pd.read_sql_query(text(query), engine)\n",
    "        engine.dispose()\n",
    "        return result_df\n",
    "    \n",
    "    def _export_results(self, df, export_path):\n",
    "        \"\"\"Export query results to file\"\"\"\n",
    "        try:\n",
    "            if export_path.endswith('.csv'):\n",
    "                df.to_csv(export_path, index=False)\n",
    "                print(f\"💾 Results exported to {export_path}\")\n",
    "            elif export_path.endswith(('.xlsx', '.xls')):\n",
    "                df.to_excel(export_path, index=False)\n",
    "                print(f\"💾 Results exported to {export_path}\")\n",
    "            else:\n",
    "                print(f\"❌ Unsupported export format. Use .csv or .xlsx\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Export failed: {e}\")\n",
    "    \n",
    "    def quick_table_query(self, database_name, table_name, columns=\"*\", where_clause=\"\", limit=10):\n",
    "        \"\"\"Generate and execute a quick SELECT query\"\"\"\n",
    "        \n",
    "        if where_clause and not where_clause.upper().strip().startswith('WHERE'):\n",
    "            where_clause = f\"WHERE {where_clause}\"\n",
    "        \n",
    "        query = f\"SELECT {columns} FROM {table_name} {where_clause}\".strip()\n",
    "        \n",
    "        return self.execute_query(database_name, query, limit=limit)\n",
    "    \n",
    "    def show_query_history(self):\n",
    "        \"\"\"Display query execution history\"\"\"\n",
    "        if not self.query_history:\n",
    "            print(\"No query history available.\")\n",
    "            return\n",
    "        \n",
    "        print(\"QUERY HISTORY:\")\n",
    "        print(\"=\" * 80)\n",
    "        for i, entry in enumerate(self.query_history[-10:], 1):  # Show last 10\n",
    "            timestamp = entry['timestamp'].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            query_preview = entry['query'][:50] + \"...\" if len(entry['query']) > 50 else entry['query']\n",
    "            print(f\"{i}. [{timestamp}] {entry['database']} - {entry['rows_returned']} rows\")\n",
    "            print(f\"   Query: {query_preview}\")\n",
    "            print()\n",
    "    \n",
    "    def get_database_info(self, database_name):\n",
    "        \"\"\"Get quick info about a database\"\"\"\n",
    "        if database_name not in self.connections:\n",
    "            print(f\"❌ Database '{database_name}' not found\")\n",
    "            return\n",
    "        \n",
    "        conn_info = self.connections[database_name]\n",
    "        \n",
    "        try:\n",
    "            if conn_info['type'] == 'sqlite':\n",
    "                query = \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "            elif conn_info['type'] == 'postgresql':\n",
    "                query = \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\"\n",
    "            elif conn_info['type'] == 'sqlserver':\n",
    "                query = \"\"\"SELECT TABLE_SCHEMA + '.' + TABLE_NAME as full_name \n",
    "                          FROM INFORMATION_SCHEMA.TABLES \n",
    "                          WHERE TABLE_TYPE = 'BASE TABLE' \n",
    "                          ORDER BY TABLE_SCHEMA, TABLE_NAME\"\"\"\n",
    "            \n",
    "            tables_df = self.execute_query(database_name, query, limit=50)\n",
    "            \n",
    "            if tables_df is not None:\n",
    "                print(f\"\\n📊 Database '{database_name}' has {len(tables_df)} tables\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error getting database info: {e}\")\n",
    "\n",
    "# Initialize Query Builder\n",
    "print(\"🚀 MULTI-DATABASE QUERY BUILDER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query_builder = MultiDatabaseQueryBuilder()\n",
    "\n",
    "# Auto-setup connections from environment variables\n",
    "print(\"Setting up database connections...\")\n",
    "\n",
    "# SQL Server connection (primary)\n",
    "sqlserver_url = os.getenv('SQLSERVER_URL')\n",
    "if sqlserver_url:\n",
    "    query_builder.add_sqlserver_connection('adventureworks', sqlserver_url)\n",
    "else:\n",
    "    # Fallback to direct connection\n",
    "    sqlserver_url = \"mssql+pyodbc://localhost\\\\SQLEXPRESS/AdventureWorks2022?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\"\n",
    "    query_builder.add_sqlserver_connection('adventureworks', sqlserver_url)\n",
    "\n",
    "# PostgreSQL connection (if available)\n",
    "postgres_url = os.getenv('DATABASE_URL')\n",
    "if postgres_url:\n",
    "    query_builder.add_postgresql_connection('postgres_db', postgres_url)\n",
    "\n",
    "# SQLite connection (if file exists)\n",
    "sqlite_files = ['business_data.db', 'sample.db', 'data.db']\n",
    "for db_file in sqlite_files:\n",
    "    if os.path.exists(db_file):\n",
    "        query_builder.add_sqlite_connection(f'sqlite_{db_file.replace(\".\", \"_\")}', db_file)\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "query_builder.list_connections()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXAMPLE USAGE:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "# List all connections\n",
    "query_builder.list_connections()\n",
    "\n",
    "# Get database info\n",
    "query_builder.get_database_info('adventureworks')\n",
    "\n",
    "# Quick table query\n",
    "query_builder.quick_table_query('adventureworks', 'dbo.AWBuildVersion')\n",
    "\n",
    "# Custom SQL query\n",
    "query = '''\n",
    "SELECT TABLE_SCHEMA, COUNT(*) as table_count \n",
    "FROM INFORMATION_SCHEMA.TABLES \n",
    "WHERE TABLE_TYPE = 'BASE TABLE'\n",
    "GROUP BY TABLE_SCHEMA\n",
    "'''\n",
    "query_builder.execute_query('adventureworks', query)\n",
    "\n",
    "# Query with export\n",
    "query_builder.execute_query('adventureworks', \n",
    "    'SELECT TOP 100 * FROM dbo.DatabaseLog ORDER BY PostTime DESC',\n",
    "    export_to='database_log.csv')\n",
    "\n",
    "# Complex query example for AdventureWorks\n",
    "complex_query = '''\n",
    "SELECT \n",
    "    p.Name as ProductName,\n",
    "    pc.Name as CategoryName,\n",
    "    p.ListPrice,\n",
    "    p.Color\n",
    "FROM Production.Product p\n",
    "JOIN Production.ProductSubcategory ps ON p.ProductSubcategoryID = ps.ProductSubcategoryID  \n",
    "JOIN Production.ProductCategory pc ON ps.ProductCategoryID = pc.ProductCategoryID\n",
    "WHERE p.ListPrice > 0\n",
    "ORDER BY p.ListPrice DESC\n",
    "'''\n",
    "query_builder.execute_query('adventureworks', complex_query, limit=20)\n",
    "\n",
    "# Show query history\n",
    "query_builder.show_query_history()\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"💡 TIPS:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"• Use schema.table format for SQL Server (e.g., 'Person.Address')\")\n",
    "print(\"• Queries automatically get LIMIT/TOP clauses for safety\")\n",
    "print(\"• Export results to CSV or Excel with export_to parameter\")\n",
    "print(\"• Use quick_table_query() for simple SELECT statements\")\n",
    "print(\"• Check query_history to see past executions\")\n",
    "print(\"• SQL Server tables: Person, Sales, Production, HumanResources schemas\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
