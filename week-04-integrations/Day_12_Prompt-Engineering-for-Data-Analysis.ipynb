{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1337ef68",
   "metadata": {},
   "source": [
    "#### Why Prompt Engineering Matters\n",
    "\n",
    "- Consistency: Get reliable insights every time\n",
    "- Accuracy: Reduce AI hallucinations and errors\n",
    "- Efficiency: Better results with fewer API calls\n",
    "- Business value: Insights that drive real decisions\n",
    "\n",
    "#### Chain-of-Thought Prompting for Data Analysis:\n",
    "What it is: A prompting technique that asks the AI to show its reasoning process step-by-step, like thinking out loud.\n",
    "\n",
    "How it works:\n",
    "- You explicitly ask the AI to break down its analysis into logical steps\n",
    "- The AI explains its reasoning at each stage\n",
    "- Creates a transparent pathway from data to insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_of_thought_analysis(df, business_question):\n",
    "    \"\"\"Use chain-of-thought prompting for deeper analysis\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    I need to analyze this business data step by step.\n",
    "    \n",
    "    Data overview:\n",
    "    - Shape: {df.shape}\n",
    "    - Columns: {list(df.columns)}\n",
    "    - Sample: {df.head(3).to_dict('records')}\n",
    "    \n",
    "    Business question: {business_question}\n",
    "    \n",
    "    Please analyze this step by step:\n",
    "    \n",
    "    Step 1: Data Understanding\n",
    "    - What does each column represent?\n",
    "    - What is the grain of this data?\n",
    "    - What time period does this cover?\n",
    "    \n",
    "    Step 2: Pattern Identification\n",
    "    - What patterns do you see in the numbers?\n",
    "    - Are there any obvious trends or seasonality?\n",
    "    - What stands out as unusual?\n",
    "    \n",
    "    Step 3: Business Context\n",
    "    - What business processes generated this data?\n",
    "    - What external factors might influence these numbers?\n",
    "    - What are the key business metrics here?\n",
    "    \n",
    "    Step 4: Insights and Recommendations\n",
    "    - What are the 3 most important insights?\n",
    "    - What actions should the business take?\n",
    "    - What additional data would be helpful?\n",
    "    \n",
    "    Step 5: Risk Assessment\n",
    "    - What assumptions am I making?\n",
    "    - What could I be missing?\n",
    "    - How confident am I in these insights?\n",
    "    \n",
    "    Walk through each step clearly and show your reasoning.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a senior data analyst who thinks step-by-step and shows all reasoning.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=800,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error in analysis: {e}\"\n",
    "\n",
    "# Test chain-of-thought analysis\n",
    "cot_analysis = chain_of_thought_analysis(sales_data, \"How can we improve our regional sales performance?\")\n",
    "print(\"Chain-of-Thought Analysis:\")\n",
    "print(cot_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606b2f7a",
   "metadata": {},
   "source": [
    "#### Few-Shot Learning for Consistent Insights\n",
    "What it is: A technique where you provide the AI with examples of the exact format and quality you want, then ask it to follow that pattern.\n",
    "\n",
    "How it works:\n",
    "- You show 2-3 examples of perfect responses\n",
    "- The AI learns the pattern and applies it to new data\n",
    "- Ensures consistent output format and quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8149154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_data_analysis(df, analysis_request):\n",
    "    \"\"\"Use few-shot learning for consistent analysis format\"\"\"\n",
    "    \n",
    "    # Provide examples of good analysis\n",
    "    examples = \"\"\"\n",
    "    Example 1:\n",
    "    Data: Customer retention by month\n",
    "    Analysis:\n",
    "    - TREND: Retention declining from 85% to 78% over 6 months\n",
    "    - ROOT CAUSE: Likely onboarding issues or product changes in March\n",
    "    - IMPACT: $50K monthly revenue at risk if trend continues\n",
    "    - ACTION: Investigate March product changes and improve onboarding\n",
    "    - METRIC: Track 30-day retention rate weekly\n",
    "    \n",
    "    Example 2:\n",
    "    Data: Website conversion rates by source\n",
    "    Analysis:\n",
    "    - TREND: Paid search converting 3.2% vs 1.8% organic\n",
    "    - ROOT CAUSE: Better keyword targeting and landing page alignment\n",
    "    - IMPACT: Paid search ROI is 180%, organic needs improvement\n",
    "    - ACTION: Apply paid search insights to organic content strategy\n",
    "    - METRIC: Monitor conversion rate by source weekly\n",
    "    \"\"\"\n",
    "    \n",
    "    data_summary = f\"\"\"\n",
    "    Current Data:\n",
    "    Shape: {df.shape}\n",
    "    Columns: {list(df.columns)}\n",
    "    Sample: {df.head(3).to_dict('records')}\n",
    "    \n",
    "    Analysis Request: {analysis_request}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    {examples}\n",
    "    \n",
    "    Now analyze this data using the same format (TREND, ROOT CAUSE, IMPACT, ACTION, METRIC):\n",
    "    \n",
    "    {data_summary}\n",
    "    \n",
    "    Provide a structured analysis following the exact format shown in the examples.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a data analyst who provides structured insights using the TREND-ROOT CAUSE-IMPACT-ACTION-METRIC format.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=400,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error in few-shot analysis: {e}\"\n",
    "\n",
    "# Test few-shot analysis\n",
    "few_shot_results = few_shot_data_analysis(sales_data, \"Analyze regional sales performance for strategic planning\")\n",
    "print(\"Few-Shot Analysis:\")\n",
    "print(few_shot_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2cf93f",
   "metadata": {},
   "source": [
    "#### When to Use Each\n",
    "Use Chain-of-Thought when:\n",
    "\n",
    "- Analyzing complex business problems\n",
    "- You need to validate AI reasoning\n",
    "- Working with unfamiliar data patterns\n",
    "- Explaining analysis to stakeholders\n",
    "\n",
    "Use Few-Shot Learning when:\n",
    "\n",
    "- Creating standardized reports\n",
    "- Need consistent analysis format\n",
    "- Training AI for specific business contexts\n",
    "- Ensuring all key metrics are included\n",
    "\n",
    "Combining Both Techniques\n",
    "\n",
    "The most powerful approach often combines both:\n",
    "```python\n",
    "def hybrid_analysis(df, question):\n",
    "    \"\"\"Combine chain-of-thought reasoning with few-shot formatting\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    First, here are examples of our standard analysis format:\n",
    "    \n",
    "    Example: Sales Analysis\n",
    "    - TREND: Clear pattern description\n",
    "    - ROOT CAUSE: Likely explanation\n",
    "    - IMPACT: Business consequences\n",
    "    - ACTION: Specific next steps\n",
    "    - METRIC: How to track progress\n",
    "    \n",
    "    Now, analyze this data step-by-step, then format your final answer using the standard format above:\n",
    "    \n",
    "    Step 1: Examine the data patterns...\n",
    "    Step 2: Consider business context...\n",
    "    Step 3: Identify key insights...\n",
    "    \n",
    "    Then provide your final analysis in the TREND-ROOT CAUSE-IMPACT-ACTION-METRIC format.\n",
    "    \n",
    "    Data: {df.head().to_string()}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2538d228",
   "metadata": {},
   "source": [
    "#### Role-Based Prompting for Different Audiences\n",
    "\n",
    "##### Role-Based Prompting Explained\n",
    "What it is: Instructing the AI to adopt a specific professional persona and perspective when analyzing data.\n",
    "\n",
    "How it works:\n",
    "- You tell the AI to \"act as\" a specific role (CEO, Sales Manager, Data Scientist, etc.)\n",
    "- The AI adjusts its language, focus areas, and recommendations to match that role's needs\n",
    "- Same data gets interpreted through different professional lenses\n",
    "\n",
    "When to Use Role-Based Prompting\n",
    "\n",
    "Primary Use Cases:\n",
    "- Multi-Stakeholder Reports: Same analysis for different audiences\n",
    "- Presentation Adaptation: Adjusting technical findings for business leaders\n",
    "- Decision Support: Getting perspectives from different functional areas\n",
    "- Training AI Systems: Teaching AI to understand different business contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461b79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoleBasedAnalyst:\n",
    "    \"\"\"Generate analysis for different business roles\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.roles = {\n",
    "            'ceo': {\n",
    "                'persona': \"You are a CEO who needs high-level strategic insights.\",\n",
    "                'focus': \"Strategic implications, competitive advantage, major risks and opportunities\",\n",
    "                'format': \"Executive summary with 3 key points and recommended actions\"\n",
    "            },\n",
    "            'sales_manager': {\n",
    "                'persona': \"You are a Sales Manager who needs actionable sales insights.\",\n",
    "                'focus': \"Sales performance, team productivity, customer behavior, revenue optimization\",\n",
    "                'format': \"Tactical recommendations with specific metrics and targets\"\n",
    "            },\n",
    "            'data_scientist': {\n",
    "                'persona': \"You are a Data Scientist who needs technical analysis.\",\n",
    "                'focus': \"Statistical patterns, data quality, modeling opportunities, technical recommendations\",\n",
    "                'format': \"Technical analysis with statistical insights and methodology suggestions\"\n",
    "            },\n",
    "            'operations': {\n",
    "                'persona': \"You are an Operations Manager who needs process insights.\",\n",
    "                'focus': \"Efficiency, bottlenecks, resource allocation, process improvements\",\n",
    "                'format': \"Operational recommendations with process optimization focus\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def analyze_for_role(self, df, role, question):\n",
    "        \"\"\"Generate role-specific analysis\"\"\"\n",
    "        \n",
    "        if role not in self.roles:\n",
    "            return f\"Role '{role}' not supported. Available roles: {list(self.roles.keys())}\"\n",
    "        \n",
    "        role_config = self.roles[role]\n",
    "        \n",
    "        data_context = f\"\"\"\n",
    "        Data Summary:\n",
    "        - Records: {df.shape[0]}\n",
    "        - Metrics: {list(df.columns)}\n",
    "        - Sample: {df.head(2).to_dict('records')}\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        {role_config['persona']}\n",
    "        \n",
    "        Focus on: {role_config['focus']}\n",
    "        Format: {role_config['format']}\n",
    "        \n",
    "        {data_context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Provide analysis appropriate for a {role.replace('_', ' ').title()}.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": role_config['persona']},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=400,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "        \n",
    "        except Exception as e:\n",
    "            return f\"Error in role-based analysis: {e}\"\n",
    "\n",
    "# Test role-based analysis\n",
    "role_analyst = RoleBasedAnalyst()\n",
    "\n",
    "# Same data, different perspectives\n",
    "ceo_view = role_analyst.analyze_for_role(sales_data, 'ceo', 'What should we prioritize for next quarter?')\n",
    "sales_view = role_analyst.analyze_for_role(sales_data, 'sales_manager', 'How can we improve team performance?')\n",
    "\n",
    "print(\"CEO Perspective:\")\n",
    "print(ceo_view)\n",
    "print(\"\\nSales Manager Perspective:\")\n",
    "print(sales_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0ec65",
   "metadata": {},
   "source": [
    "#### How All Three Techniques Relate\n",
    "\n",
    "Think of them as layered approaches that can be combined:\n",
    "\n",
    "- Role-Based Prompting = WHO is doing the analysis\n",
    "- Chain-of-Thought = HOW to think through the problem  \n",
    "- Few-Shot Learning = WHAT the output format should be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f190f29e",
   "metadata": {},
   "source": [
    "### Production-Ready Prompting Patterns\n",
    "##### Template-Based Prompt Management\n",
    "\n",
    "Use any of the four template types by changing the first argument in `analyze_with_template()`. Each template expects different keyword arguments based on its `variables` list.  Pull the data to a string format for each templates required `variables` (defined in the `variables` list), to provide the right keyword arguments for whichever template chosen to execute. \n",
    "\n",
    "The templates are taking pandas analysis results and asking an LLM to provide business interpretation of the patterns found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db577b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplateManager:\n",
    "    \"\"\"Manage reusable prompt templates for consistent analysis\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.templates = {\n",
    "            'sql_explainer': {\n",
    "                'system': \"You are a database expert who explains SQL queries in business terms.\",\n",
    "                'template': \"\"\"\n",
    "                SQL Query:\n",
    "                {query}\n",
    "                \n",
    "                Results Summary:\n",
    "                - Records returned: {row_count}\n",
    "                - Key columns: {columns}\n",
    "                \n",
    "                Please explain:\n",
    "                1. What business question this query answers\n",
    "                2. Key insights from the results\n",
    "                3. Potential follow-up questions\n",
    "                4. Any data quality concerns\n",
    "                \n",
    "                Keep explanations clear for non-technical stakeholders.\n",
    "                \"\"\",\n",
    "                'variables': ['query', 'row_count', 'columns']\n",
    "            },\n",
    "            \n",
    "            'anomaly_detector': {\n",
    "                'system': \"You are a statistical analyst expert at identifying unusual patterns in business data.\",\n",
    "                'template': \"\"\"\n",
    "                Dataset: {dataset_name}\n",
    "                Metric: {metric_name}\n",
    "                \n",
    "                Statistical Summary:\n",
    "                - Mean: {mean:.2f}\n",
    "                - Standard Deviation: {std:.2f}\n",
    "                - Min/Max: {min_val:.2f} / {max_val:.2f}\n",
    "                - Outlier threshold: {outlier_threshold:.2f}\n",
    "                \n",
    "                Potential Outliers:\n",
    "                {outliers}\n",
    "                \n",
    "                Analysis needed:\n",
    "                1. Are these outliers legitimate or data errors?\n",
    "                2. What business events might explain unusual values?\n",
    "                3. Should we investigate further?\n",
    "                4. How might this impact business decisions?\n",
    "                \n",
    "                Focus on business implications, not just statistics.\n",
    "                \"\"\",\n",
    "                'variables': ['dataset_name', 'metric_name', 'mean', 'std', 'min_val', 'max_val', 'outlier_threshold', 'outliers']\n",
    "            },\n",
    "            \n",
    "            'trend_analyzer': {\n",
    "                'system': \"You are a business analyst who identifies trends and predicts business implications.\",\n",
    "                'template': \"\"\"\n",
    "                Time Series Data: {data_description}\n",
    "                Time Period: {time_period}\n",
    "                \n",
    "                Trend Analysis:\n",
    "                {trend_data}\n",
    "                \n",
    "                Please provide:\n",
    "                1. TREND IDENTIFICATION: What patterns do you see?\n",
    "                2. BUSINESS DRIVERS: What might be causing these trends?\n",
    "                3. FUTURE IMPLICATIONS: What should we expect next?\n",
    "                4. RECOMMENDED ACTIONS: What should the business do?\n",
    "                5. MONITORING METRICS: What should we track going forward?\n",
    "                \n",
    "                Consider seasonality, external factors, and business context.\n",
    "                \"\"\",\n",
    "                'variables': ['data_description', 'time_period', 'trend_data']\n",
    "            },\n",
    "            \n",
    "            'comparative_analysis': {\n",
    "                'system': \"You are a strategic analyst who compares performance across different segments.\",\n",
    "                'template': \"\"\"\n",
    "                Comparison Analysis: {analysis_title}\n",
    "                \n",
    "                Segments Being Compared:\n",
    "                {segments_data}\n",
    "                \n",
    "                Key Metrics:\n",
    "                {metrics_summary}\n",
    "                \n",
    "                Provide structured comparison:\n",
    "                1. TOP PERFORMERS: Which segments are leading and why?\n",
    "                2. UNDERPERFORMERS: Which segments need attention?\n",
    "                3. KEY DIFFERENCES: What explains the performance gaps?\n",
    "                4. OPPORTUNITIES: Where can we improve quickly?\n",
    "                5. RESOURCE ALLOCATION: How should we prioritize investments?\n",
    "                \n",
    "                Make recommendations specific and actionable.\n",
    "                \"\"\",\n",
    "                'variables': ['analysis_title', 'segments_data', 'metrics_summary']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_prompt(self, template_name, **kwargs):\n",
    "        \"\"\"Generate prompt from template with variables\"\"\"\n",
    "        if template_name not in self.templates:\n",
    "            raise ValueError(f\"Template '{template_name}' not found\")\n",
    "        \n",
    "        template = self.templates[template_name]\n",
    "        \n",
    "        # Check required variables\n",
    "        missing_vars = [var for var in template['variables'] if var not in kwargs]\n",
    "        if missing_vars:\n",
    "            raise ValueError(f\"Missing required variables: {missing_vars}\")\n",
    "        \n",
    "        # Format the template\n",
    "        formatted_prompt = template['template'].format(**kwargs)\n",
    "        \n",
    "        return {\n",
    "            'system': template['system'],\n",
    "            'user': formatted_prompt\n",
    "        }\n",
    "    \n",
    "    def analyze_with_template(self, template_name, **kwargs):\n",
    "        \"\"\"Execute analysis using template\"\"\"\n",
    "        prompt_data = self.get_prompt(template_name, **kwargs)\n",
    "        \n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt_data['system']},\n",
    "                    {\"role\": \"user\", \"content\": prompt_data['user']}\n",
    "                ],\n",
    "                max_tokens=600,\n",
    "                temperature=0.2\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "        \n",
    "        except Exception as e:\n",
    "            return f\"Template analysis error: {e}\"\n",
    "\n",
    "# Example usage\n",
    "prompt_manager = PromptTemplateManager()\n",
    "\n",
    "# Analyze SQL query results\n",
    "sql_analysis = prompt_manager.analyze_with_template(\n",
    "    'sql_explainer',\n",
    "    query=\"SELECT region, SUM(revenue) FROM sales GROUP BY region ORDER BY SUM(revenue) DESC\",\n",
    "    row_count=5,\n",
    "    columns=\"region, total_revenue\"\n",
    ")\n",
    "\n",
    "print(\"SQL Query Analysis:\")\n",
    "print(sql_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1cc85e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7adfb8bf",
   "metadata": {},
   "source": [
    "#### Combining All Three Techniques: Roles, Few-shot and Chain-of-thought\n",
    "\n",
    "Here's how they work together in practice:\n",
    "\n",
    "AI-Enhanced SQL Reporter with all three techniques:\n",
    "\n",
    "```python\n",
    "def comprehensive_business_analysis(df, sql_query, target_audience, business_context):\n",
    "    \"\"\"\n",
    "    Role-based: Adapt for target audience (CEO, Sales, Operations)\n",
    "    Chain-of-thought: Show analytical reasoning  \n",
    "    Few-shot: Consistent report format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Role configuration\n",
    "    role_configs = {\n",
    "        'ceo': {\n",
    "            'persona': 'strategic executive focused on competitive advantage',\n",
    "            'priorities': ['revenue impact', 'market position', 'resource allocation']\n",
    "        },\n",
    "        'sales': {\n",
    "            'persona': 'sales leader focused on team performance and targets',\n",
    "            'priorities': ['quota attainment', 'pipeline health', 'conversion rates']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Few-shot examples for consistency\n",
    "    example_format = \"\"\"\n",
    "    - INSIGHT: Key finding with context\n",
    "    - IMPLICATION: What this means for the business\n",
    "    - ACTION: Specific next step with timeline\n",
    "    - METRIC: How to track success\n",
    "    \"\"\"\n",
    "    \n",
    "    # Chain-of-thought reasoning structure\n",
    "    reasoning_steps = \"\"\"\n",
    "    Step 1: Data Quality Assessment\n",
    "    Step 2: Pattern Recognition  \n",
    "    Step 3: Business Context Integration\n",
    "    Step 4: Strategic Recommendations\n",
    "    \"\"\"\n",
    "    \n",
    "    # This creates analysis that is:\n",
    "    # - Appropriate for the audience (role-based)\n",
    "    # - Shows clear reasoning (chain-of-thought)  \n",
    "    # - Consistently formatted (few-shot)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83933551",
   "metadata": {},
   "source": [
    "Client Consulting Work:\n",
    "```python\n",
    "# Adapt your analysis to client's organizational structure\n",
    "def client_analysis(df, client_role, urgency=\"normal\"):\n",
    "    roles = {\n",
    "        'startup_ceo': \"fast decisions, resource constraints, growth focus\",\n",
    "        'enterprise_manager': \"risk mitigation, compliance, scalability\", \n",
    "        'nonprofit_director': \"impact measurement, donor relations, efficiency\"\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc437de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class AdvancedAIAnalyzer:\n",
    "    \"\"\"\n",
    "    Combines Chain-of-Thought, Few-Shot Learning, and Role-Based prompting\n",
    "    for comprehensive database analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key=None):\n",
    "        \"\"\"Initialize with OpenAI API key\"\"\"\n",
    "        api_key = openai_api_key or os.getenv('OPENAI_API_KEY')\n",
    "        \n",
    "        if not api_key:\n",
    "            raise ValueError(\"OpenAI API key required. Set OPENAI_API_KEY environment variable.\")\n",
    "        \n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        \n",
    "        # Role configurations\n",
    "        self.roles = {\n",
    "            'ceo': {\n",
    "                'persona': 'You are a CEO focused on strategic decisions, competitive advantage, and high-level business impact.',\n",
    "                'focus': 'Strategic implications, market opportunities, major risks, resource allocation, competitive positioning',\n",
    "                'format': 'Executive summary with strategic priorities and board-level recommendations',\n",
    "                'priorities': ['revenue growth', 'market share', 'competitive advantage', 'strategic risks']\n",
    "            },\n",
    "            'sales_director': {\n",
    "                'persona': 'You are a Sales Director focused on revenue optimization, team performance, and customer relationships.',\n",
    "                'focus': 'Sales performance, customer behavior, pipeline health, territory management, conversion optimization',\n",
    "                'format': 'Sales-focused insights with actionable tactics and performance metrics',\n",
    "                'priorities': ['quota attainment', 'customer acquisition', 'deal velocity', 'team productivity']\n",
    "            },\n",
    "            'operations_manager': {\n",
    "                'persona': 'You are an Operations Manager focused on efficiency, process optimization, and cost management.',\n",
    "                'focus': 'Operational efficiency, process bottlenecks, cost optimization, resource utilization, quality metrics',\n",
    "                'format': 'Operational recommendations with process improvements and efficiency gains',\n",
    "                'priorities': ['cost reduction', 'process efficiency', 'quality improvement', 'resource optimization']\n",
    "            },\n",
    "            'data_scientist': {\n",
    "                'persona': 'You are a Senior Data Scientist focused on statistical patterns, predictive opportunities, and technical insights.',\n",
    "                'focus': 'Statistical significance, correlation patterns, predictive modeling opportunities, data quality, technical recommendations',\n",
    "                'format': 'Technical analysis with statistical insights and modeling recommendations',\n",
    "                'priorities': ['statistical patterns', 'predictive opportunities', 'data quality', 'analytical methods']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Few-shot examples for consistent formatting\n",
    "        self.few_shot_examples = {\n",
    "            'business_analysis': \"\"\"\n",
    "Example 1 - Customer Retention Analysis:\n",
    "• TREND: Customer retention dropped from 87% to 82% over 6 months\n",
    "• ROOT CAUSE: Product quality issues and increased competitor pricing pressure\n",
    "• IMPACT: $2.3M annual revenue at risk if trend continues\n",
    "• ACTION: Implement customer success program and review pricing strategy\n",
    "• METRIC: Track monthly retention rate and customer satisfaction scores\n",
    "\n",
    "Example 2 - Sales Performance Analysis:\n",
    "• TREND: Q3 sales up 15% YoY but down 8% from Q2 seasonally adjusted\n",
    "• ROOT CAUSE: Strong new customer acquisition offset by declining average deal size\n",
    "• IMPACT: Revenue growth slowing, margin pressure from smaller deals\n",
    "• ACTION: Focus on upselling existing customers and premium product positioning\n",
    "• METRIC: Monitor average deal size and customer lifetime value monthly\n",
    "\"\"\",\n",
    "            'operational_analysis': \"\"\"\n",
    "Example 1 - Inventory Analysis:\n",
    "• EFFICIENCY: Inventory turnover improved to 8.2x from 6.1x last year\n",
    "• BOTTLENECK: Warehouse capacity constraining faster fulfillment in peak periods\n",
    "• COST IMPACT: $450K in carrying cost savings, but $200K in lost sales from stockouts\n",
    "• OPTIMIZATION: Implement demand forecasting and expand warehouse capacity by 25%\n",
    "• KPI: Track inventory turnover, stockout rate, and fulfillment time\n",
    "\n",
    "Example 2 - Order Processing Analysis:\n",
    "• EFFICIENCY: Order processing time reduced from 2.1 to 1.4 days average\n",
    "• BOTTLENECK: Manual credit checks causing 30% of delays\n",
    "• COST IMPACT: Faster processing improved customer satisfaction by 12%\n",
    "• OPTIMIZATION: Automate credit approval for orders under $5K\n",
    "• KPI: Monitor processing time, manual intervention rate, customer satisfaction\n",
    "\"\"\"\n",
    "        }\n",
    "    \n",
    "    def connect_to_worldwideimporters(self, server='localhost\\\\SQLEXPRESS', database='WideWorldImporters'):\n",
    "        \"\"\"Connect to SQL Server WorldWideImporters database\"\"\"\n",
    "        try:\n",
    "            connection_string = f\"\"\"\n",
    "            DRIVER={{ODBC Driver 17 for SQL Server}};\n",
    "            SERVER={server};\n",
    "            DATABASE={database};\n",
    "            Trusted_Connection=yes;\n",
    "            \"\"\"\n",
    "            \n",
    "            self.connection = pyodbc.connect(connection_string)\n",
    "            print(f\"✅ Connected to {database} database successfully!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Database connection failed: {e}\")\n",
    "            print(\"\\nTroubleshooting tips:\")\n",
    "            print(\"1. Ensure SQL Server is running\")\n",
    "            print(\"2. Verify database name: WideWorldImporters\")\n",
    "            print(\"3. Check if ODBC Driver 17 for SQL Server is installed\")\n",
    "            print(\"4. Try different server name format if needed\")\n",
    "            print(\"5. Try server name: 'localhost' or '.' or your computer name\")\n",
    "            return False\n",
    "    \n",
    "    def execute_query(self, query):\n",
    "        \"\"\"Execute SQL query and return DataFrame\"\"\"\n",
    "        try:\n",
    "            # Suppress the pandas warning by using the connection directly\n",
    "            with pd.option_context('mode.chained_assignment', None):\n",
    "                df = pd.read_sql_query(query, self.connection)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Query execution error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def chain_of_thought_analysis(self, df, query, business_question):\n",
    "        \"\"\"Apply chain-of-thought reasoning to data analysis\"\"\"\n",
    "        \n",
    "        data_summary = f\"\"\"\n",
    "Data Overview:\n",
    "- Records: {df.shape[0]:,}\n",
    "- Columns: {list(df.columns)}\n",
    "- Date Range: {self._get_date_range(df)}\n",
    "- Sample Records: {df.head(3).to_dict('records')}\n",
    "\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "SQL Query Executed:\n",
    "{query}\n",
    "\n",
    "{data_summary}\n",
    "\n",
    "Business Question: {business_question}\n",
    "\n",
    "Please analyze this step-by-step using chain-of-thought reasoning:\n",
    "\n",
    "STEP 1: DATA COMPREHENSION\n",
    "- What business processes does this data represent?\n",
    "- What is the grain/level of this data?\n",
    "- What time period and scope does this cover?\n",
    "- Are there any immediate data quality observations?\n",
    "\n",
    "STEP 2: PATTERN RECOGNITION\n",
    "- What numerical patterns, trends, or distributions do you observe?\n",
    "- Are there any seasonal, cyclical, or temporal patterns?\n",
    "- What outliers or anomalies stand out?\n",
    "- How do different segments or categories compare?\n",
    "\n",
    "STEP 3: BUSINESS CONTEXT ANALYSIS\n",
    "- What external business factors could influence these patterns?\n",
    "- How do these numbers relate to typical business performance?\n",
    "- What competitive or market dynamics might be at play?\n",
    "- What operational processes could drive these results?\n",
    "\n",
    "STEP 4: INSIGHT SYNTHESIS\n",
    "- What are the 3 most significant insights from this analysis?\n",
    "- What cause-and-effect relationships can you identify?\n",
    "- What assumptions am I making, and how confident am I?\n",
    "- What questions does this analysis raise?\n",
    "\n",
    "STEP 5: STRATEGIC IMPLICATIONS\n",
    "- What business decisions should this data inform?\n",
    "- What actions would have the highest impact?\n",
    "- What risks or opportunities does this reveal?\n",
    "- What additional analysis would be valuable?\n",
    "\n",
    "Show your complete reasoning process for each step.\n",
    "\"\"\"\n",
    "        \n",
    "        return self._make_api_call(prompt, system_message=\"You are a senior business analyst who thinks step-by-step and shows detailed reasoning for data analysis.\")\n",
    "    \n",
    "    def few_shot_analysis(self, df, query, analysis_type='business_analysis'):\n",
    "        \"\"\"Apply few-shot learning for consistent analysis format\"\"\"\n",
    "        \n",
    "        examples = self.few_shot_examples.get(analysis_type, self.few_shot_examples['business_analysis'])\n",
    "        \n",
    "        data_context = f\"\"\"\n",
    "Query: {query}\n",
    "Results: {df.shape[0]} records, {df.shape[1]} columns\n",
    "Sample Data: {df.head(3).to_dict('records')}\n",
    "Key Metrics: {list(df.select_dtypes(include=['number']).columns)}\n",
    "\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Here are examples of high-quality business analysis format:\n",
    "\n",
    "{examples}\n",
    "\n",
    "Now analyze this data using the exact same structured format:\n",
    "\n",
    "{data_context}\n",
    "\n",
    "Provide your analysis following the same pattern as the examples above:\n",
    "• TREND: [Clear description of main pattern/trend]\n",
    "• ROOT CAUSE: [Most likely explanation for the trend]  \n",
    "• IMPACT: [Business consequences with quantification where possible]\n",
    "• ACTION: [Specific recommended next steps with timeline]\n",
    "• METRIC: [How to track progress and success]\n",
    "\n",
    "Focus on actionable business insights with specific recommendations.\n",
    "\"\"\"\n",
    "        \n",
    "        return self._make_api_call(prompt, system_message=\"You are a business analyst who provides structured insights using the TREND-ROOT CAUSE-IMPACT-ACTION-METRIC format.\")\n",
    "    \n",
    "    def role_based_analysis(self, df, query, role, business_context):\n",
    "        \"\"\"Generate role-specific analysis\"\"\"\n",
    "        \n",
    "        if role not in self.roles:\n",
    "            return f\"Role '{role}' not supported. Available: {list(self.roles.keys())}\"\n",
    "        \n",
    "        role_config = self.roles[role]\n",
    "        \n",
    "        data_summary = f\"\"\"\n",
    "Data Context: {business_context}\n",
    "Query: {query}\n",
    "Results: {df.shape[0]} records with columns: {list(df.columns)}\n",
    "Sample: {df.head(2).to_dict('records')}\n",
    "Key Numbers: {df.describe().to_dict() if len(df.select_dtypes(include=['number']).columns) > 0 else 'No numeric data'}\n",
    "\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "{role_config['persona']}\n",
    "\n",
    "Analysis Focus: {role_config['focus']}\n",
    "Key Priorities: {', '.join(role_config['priorities'])}\n",
    "Expected Format: {role_config['format']}\n",
    "\n",
    "{data_summary}\n",
    "\n",
    "Provide analysis specifically tailored for a {role.replace('_', ' ').title()}:\n",
    "\n",
    "1. EXECUTIVE SUMMARY (2-3 sentences)\n",
    "   - What does this data mean for our {role.replace('_', ' ')} priorities?\n",
    "\n",
    "2. KEY INSIGHTS (3-4 bullet points)\n",
    "   - Focus on insights most relevant to {role.replace('_', ' ')} decisions\n",
    "\n",
    "3. STRATEGIC RECOMMENDATIONS (2-3 actions)\n",
    "   - Specific actions appropriate for {role.replace('_', ' ')} authority level\n",
    "\n",
    "4. SUCCESS METRICS\n",
    "   - KPIs this role should track based on this analysis\n",
    "\n",
    "5. RISK ASSESSMENT\n",
    "   - What could go wrong? What are we missing?\n",
    "\n",
    "Tailor language, priorities, and recommendations specifically for a {role.replace('_', ' ').title()}.\n",
    "\"\"\"\n",
    "        \n",
    "        return self._make_api_call(prompt, system_message=role_config['persona'])\n",
    "    \n",
    "    def comprehensive_analysis(self, query, business_question, target_roles=['ceo', 'sales_director'], business_context=\"\"):\n",
    "        \"\"\"\n",
    "        Run complete analysis combining all three techniques\n",
    "        \"\"\"\n",
    "        print(f\"🔄 Executing comprehensive analysis...\")\n",
    "        print(f\"Query: {query[:100]}...\")\n",
    "        \n",
    "        # Execute query\n",
    "        df = self.execute_query(query)\n",
    "        if df is None or len(df) == 0:\n",
    "            return {\"error\": \"Query returned no data\"}\n",
    "        \n",
    "        print(f\"✅ Query executed: {df.shape[0]} records returned\")\n",
    "        \n",
    "        results = {\n",
    "            'query': query,\n",
    "            'business_question': business_question,\n",
    "            'data_summary': {\n",
    "                'records': df.shape[0],\n",
    "                'columns': list(df.columns),\n",
    "                'date_range': self._get_date_range(df),\n",
    "                'sample_data': df.head(3).to_dict('records')\n",
    "            },\n",
    "            'analyses': {}\n",
    "        }\n",
    "        \n",
    "        # 1. Chain-of-Thought Analysis\n",
    "        print(\"🧠 Running chain-of-thought analysis...\")\n",
    "        results['analyses']['chain_of_thought'] = self.chain_of_thought_analysis(df, query, business_question)\n",
    "        \n",
    "        # 2. Few-Shot Analysis  \n",
    "        print(\"📋 Running few-shot structured analysis...\")\n",
    "        results['analyses']['few_shot'] = self.few_shot_analysis(df, query)\n",
    "        \n",
    "        # 3. Role-Based Analyses\n",
    "        print(f\"👥 Running role-based analysis for: {', '.join(target_roles)}\")\n",
    "        results['analyses']['role_based'] = {}\n",
    "        \n",
    "        for role in target_roles:\n",
    "            print(f\"   📊 Analyzing for {role.replace('_', ' ').title()}...\")\n",
    "            results['analyses']['role_based'][role] = self.role_based_analysis(df, query, role, business_context)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _make_api_call(self, prompt, system_message=None, max_tokens=800):\n",
    "        \"\"\"Make OpenAI API call with error handling using new client\"\"\"\n",
    "        try:\n",
    "            messages = []\n",
    "            if system_message:\n",
    "                messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"API Error: {e}\"\n",
    "    \n",
    "    def _get_date_range(self, df):\n",
    "        \"\"\"Extract date range from DataFrame if date columns exist\"\"\"\n",
    "        date_columns = df.select_dtypes(include=['datetime64']).columns\n",
    "        if len(date_columns) > 0:\n",
    "            date_col = date_columns[0]\n",
    "            return f\"{df[date_col].min()} to {df[date_col].max()}\"\n",
    "        return \"No date columns found\"\n",
    "    \n",
    "    def print_comprehensive_report(self, results):\n",
    "        \"\"\"Print formatted comprehensive analysis report\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"🚀 COMPREHENSIVE AI DATABASE ANALYSIS REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\n📊 DATA SUMMARY:\")\n",
    "        print(f\"Records Analyzed: {results['data_summary']['records']:,}\")\n",
    "        print(f\"Columns: {', '.join(results['data_summary']['columns'])}\")\n",
    "        print(f\"Date Range: {results['data_summary']['date_range']}\")\n",
    "        \n",
    "        print(f\"\\n❓ BUSINESS QUESTION:\")\n",
    "        print(f\"{results['business_question']}\")\n",
    "        \n",
    "        print(f\"\\n🔍 SQL QUERY:\")\n",
    "        print(f\"{results['query']}\")\n",
    "        \n",
    "        # Chain-of-Thought Analysis\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"🧠 CHAIN-OF-THOUGHT ANALYSIS (Step-by-Step Reasoning)\")\n",
    "        print(\"=\"*60)\n",
    "        print(results['analyses']['chain_of_thought'])\n",
    "        \n",
    "        # Few-Shot Analysis\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"📋 STRUCTURED ANALYSIS (Few-Shot Learning Format)\")\n",
    "        print(\"=\"*60)\n",
    "        print(results['analyses']['few_shot'])\n",
    "        \n",
    "        # Role-Based Analyses\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"👥 ROLE-BASED PERSPECTIVES\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for role, analysis in results['analyses']['role_based'].items():\n",
    "            print(f\"\\n🎯 {role.replace('_', ' ').upper()} PERSPECTIVE:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(analysis)\n",
    "    \n",
    "    def close_connection(self):\n",
    "        \"\"\"Close database connection\"\"\"\n",
    "        if hasattr(self, 'connection'):\n",
    "            self.connection.close()\n",
    "            print(\"Database connection closed.\")\n",
    "\n",
    "\n",
    "# Sample business analysis queries for WorldWideImporters\n",
    "SAMPLE_QUERIES = {\n",
    "    'sales_performance': {\n",
    "        'query': \"\"\"\n",
    "        SELECT \n",
    "            c.CustomerCategoryName,\n",
    "            YEAR(o.OrderDate) as Year,\n",
    "            MONTH(o.OrderDate) as Month,\n",
    "            COUNT(DISTINCT o.OrderID) as OrderCount,\n",
    "            COUNT(DISTINCT o.CustomerID) as UniqueCustomers,\n",
    "            SUM(ol.Quantity * ol.UnitPrice) as TotalRevenue,\n",
    "            AVG(ol.Quantity * ol.UnitPrice) as AvgOrderValue\n",
    "        FROM Sales.Orders o\n",
    "        JOIN Sales.OrderLines ol ON o.OrderID = ol.OrderID\n",
    "        JOIN Sales.Customers cust ON o.CustomerID = cust.CustomerID\n",
    "        JOIN Sales.CustomerCategories c ON cust.CustomerCategoryID = c.CustomerCategoryID\n",
    "        WHERE o.OrderDate >= '2016-01-01'\n",
    "        GROUP BY c.CustomerCategoryName, YEAR(o.OrderDate), MONTH(o.OrderDate)\n",
    "        ORDER BY Year DESC, Month DESC, TotalRevenue DESC\n",
    "        \"\"\",\n",
    "        'business_question': 'How is our sales performance trending across different customer categories, and what opportunities exist for growth?',\n",
    "        'context': 'Monthly sales analysis for strategic planning and customer segment optimization',\n",
    "        'roles': ['ceo', 'sales_director']\n",
    "    },\n",
    "    \n",
    "    'inventory_analysis': {\n",
    "        'query': \"\"\"\n",
    "        SELECT \n",
    "            sg.StockGroupName,\n",
    "            si.StockItemName,\n",
    "            sh.QuantityOnHand,\n",
    "            sh.LastStocktakeQuantity,\n",
    "            si.UnitPrice,\n",
    "            (sh.QuantityOnHand * si.UnitPrice) as InventoryValue,\n",
    "            si.RecommendedRetailPrice - si.UnitPrice as PotentialProfit\n",
    "        FROM Warehouse.StockItemHoldings sh\n",
    "        JOIN Warehouse.StockItems si ON sh.StockItemID = si.StockItemID\n",
    "        JOIN Warehouse.StockItemStockGroups sisg ON si.StockItemID = sisg.StockItemID\n",
    "        JOIN Warehouse.StockGroups sg ON sisg.StockGroupID = sg.StockGroupID\n",
    "        WHERE sh.QuantityOnHand > 0\n",
    "        ORDER BY InventoryValue DESC\n",
    "        \"\"\",\n",
    "        'business_question': 'What is our current inventory position and how can we optimize inventory management for better profitability?',\n",
    "        'context': 'Inventory optimization analysis for operational efficiency and cash flow management',\n",
    "        'roles': ['operations_manager', 'ceo']\n",
    "    },\n",
    "    \n",
    "    'customer_behavior': {\n",
    "        'query': \"\"\"\n",
    "        SELECT \n",
    "            c.CustomerName,\n",
    "            COUNT(DISTINCT o.OrderID) as TotalOrders,\n",
    "            SUM(ol.Quantity * ol.UnitPrice) as TotalSpent,\n",
    "            AVG(ol.Quantity * ol.UnitPrice) as AvgOrderValue,\n",
    "            MIN(o.OrderDate) as FirstOrder,\n",
    "            MAX(o.OrderDate) as LastOrder,\n",
    "            DATEDIFF(day, MIN(o.OrderDate), MAX(o.OrderDate)) as CustomerLifespanDays\n",
    "        FROM Sales.Customers c\n",
    "        JOIN Sales.Orders o ON c.CustomerID = o.CustomerID\n",
    "        JOIN Sales.OrderLines ol ON o.OrderID = ol.OrderID\n",
    "        GROUP BY c.CustomerID, c.CustomerName\n",
    "        HAVING COUNT(DISTINCT o.OrderID) >= 5\n",
    "        ORDER BY TotalSpent DESC\n",
    "        \"\"\",\n",
    "        'business_question': 'Who are our most valuable customers and what patterns can we identify to improve customer retention and acquisition?',\n",
    "        'context': 'Customer lifetime value analysis for relationship management and marketing strategy',\n",
    "        'roles': ['sales_director', 'ceo', 'data_scientist']\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to demonstrate all three AI techniques with WorldWideImporters\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🚀 Advanced AI Database Analyzer\")\n",
    "    print(\"Combining Chain-of-Thought + Few-Shot Learning + Role-Based Analysis\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    try:\n",
    "        analyzer = AdvancedAIAnalyzer()\n",
    "        print(\"✅ AI Analyzer initialized successfully!\")\n",
    "    except ValueError as e:\n",
    "        print(f\"❌ {e}\")\n",
    "        print(\"\\nPlease set your OpenAI API key:\")\n",
    "        print(\"1. Create a .env file with: OPENAI_API_KEY=your_key_here\")\n",
    "        print(\"2. Or set environment variable: OPENAI_API_KEY\")\n",
    "        print(\"3. Install required packages: pip install openai>=1.0\")\n",
    "        return\n",
    "    \n",
    "    # Connect to database\n",
    "    if not analyzer.connect_to_worldwideimporters():\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Available Analysis Options:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for key, config in SAMPLE_QUERIES.items():\n",
    "        print(f\"\\n{key.upper().replace('_', ' ')}:\")\n",
    "        print(f\"Question: {config['business_question']}\")\n",
    "        print(f\"Roles: {', '.join([r.replace('_', ' ').title() for r in config['roles']])}\")\n",
    "    \n",
    "    # Let user choose analysis or run all\n",
    "    print(f\"\\nChoose analysis to run:\")\n",
    "    print(\"1. Sales Performance Analysis\")\n",
    "    print(\"2. Inventory Analysis\") \n",
    "    print(\"3. Customer Behavior Analysis\")\n",
    "    print(\"4. Run All Analyses\")\n",
    "    \n",
    "    choice = input(\"\\nEnter choice (1-4) or press Enter for Sales Performance: \").strip()\n",
    "    \n",
    "    analyses_to_run = []\n",
    "    if choice == '2':\n",
    "        analyses_to_run = ['inventory_analysis']\n",
    "    elif choice == '3':\n",
    "        analyses_to_run = ['customer_behavior']\n",
    "    elif choice == '4':\n",
    "        analyses_to_run = list(SAMPLE_QUERIES.keys())\n",
    "    else:\n",
    "        analyses_to_run = ['sales_performance']\n",
    "    \n",
    "    # Run selected analyses\n",
    "    for analysis_key in analyses_to_run:\n",
    "        config = SAMPLE_QUERIES[analysis_key]\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"🔄 RUNNING: {analysis_key.upper().replace('_', ' ')} ANALYSIS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        results = analyzer.comprehensive_analysis(\n",
    "            query=config['query'],\n",
    "            business_question=config['business_question'],\n",
    "            target_roles=config['roles'],\n",
    "            business_context=config['context']\n",
    "        )\n",
    "        \n",
    "        if 'error' in results:\n",
    "            print(f\"❌ Analysis failed: {results['error']}\")\n",
    "            continue\n",
    "        \n",
    "        # Print comprehensive report\n",
    "        analyzer.print_comprehensive_report(results)\n",
    "        \n",
    "        if len(analyses_to_run) > 1:\n",
    "            input(\"\\nPress Enter to continue to next analysis...\")\n",
    "    \n",
    "    # Cleanup\n",
    "    analyzer.close_connection()\n",
    "    print(f\"\\n✅ Analysis complete!\")\n",
    "    print(f\"\\n💡 Key Observations:\")\n",
    "    print(f\"• Chain-of-Thought: Shows step-by-step reasoning process\")\n",
    "    print(f\"• Few-Shot Learning: Provides consistent TREND-ROOT CAUSE-IMPACT-ACTION-METRIC format\")\n",
    "    print(f\"• Role-Based: Adapts insights for different business stakeholders\")\n",
    "    print(f\"\\nThis demonstrates how AI can provide multiple perspectives on the same data!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c2a51",
   "metadata": {},
   "source": [
    "For more review...this code provided by Claude AI - haven't used it in practice.\n",
    "\n",
    "#### Dynamic Prompt Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c578646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptivePromptEngine:\n",
    "    \"\"\"Automatically optimize prompts based on data characteristics\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.optimization_history = {}\n",
    "    \n",
    "    def analyze_data_characteristics(self, df):\n",
    "        \"\"\"Analyze data to determine optimal prompting strategy\"\"\"\n",
    "        characteristics = {\n",
    "            'row_count': len(df),\n",
    "            'column_count': len(df.columns),\n",
    "            'numeric_columns': len(df.select_dtypes(include=['number']).columns),\n",
    "            'categorical_columns': len(df.select_dtypes(include=['object', 'category']).columns),\n",
    "            'has_dates': any(df.dtypes == 'datetime64[ns]'),\n",
    "            'has_nulls': df.isnull().any().any(),\n",
    "            'data_size': 'small' if len(df) < 100 else 'medium' if len(df) < 1000 else 'large'\n",
    "        }\n",
    "        \n",
    "        return characteristics\n",
    "    \n",
    "    def select_optimal_approach(self, characteristics, analysis_goal):\n",
    "        \"\"\"Choose best prompting approach based on data characteristics\"\"\"\n",
    "        \n",
    "        # Small datasets: Full data analysis\n",
    "        if characteristics['data_size'] == 'small':\n",
    "            return 'full_data_analysis'\n",
    "        \n",
    "        # Large datasets: Statistical summary approach\n",
    "        elif characteristics['data_size'] == 'large':\n",
    "            return 'statistical_summary'\n",
    "        \n",
    "        # Time series data: Trend analysis\n",
    "        elif characteristics['has_dates']:\n",
    "            return 'time_series_analysis'\n",
    "        \n",
    "        # Mostly categorical: Segment analysis\n",
    "        elif characteristics['categorical_columns'] > characteristics['numeric_columns']:\n",
    "            return 'categorical_analysis'\n",
    "        \n",
    "        # Default: Balanced approach\n",
    "        else:\n",
    "            return 'balanced_analysis'\n",
    "    \n",
    "    def generate_adaptive_prompt(self, df, question, analysis_goal='general'):\n",
    "        \"\"\"Generate optimized prompt based on data characteristics\"\"\"\n",
    "        \n",
    "        characteristics = self.analyze_data_characteristics(df)\n",
    "        approach = self.select_optimal_approach(characteristics, analysis_goal)\n",
    "        \n",
    "        base_context = f\"\"\"\n",
    "        Dataset Overview:\n",
    "        - Size: {characteristics['row_count']} rows, {characteristics['column_count']} columns\n",
    "        - Numeric metrics: {characteristics['numeric_columns']}\n",
    "        - Categories: {characteristics['categorical_columns']}\n",
    "        - Data quality: {'Clean' if not characteristics['has_nulls'] else 'Has missing values'}\n",
    "        \"\"\"\n",
    "        \n",
    "        if approach == 'full_data_analysis':\n",
    "            # Small dataset - include more detail\n",
    "            data_sample = df.head(10).to_dict('records')\n",
    "            prompt = f\"\"\"\n",
    "            {base_context}\n",
    "            \n",
    "            Complete dataset sample:\n",
    "            {json.dumps(data_sample, indent=2, default=str)}\n",
    "            \n",
    "            Question: {question}\n",
    "            \n",
    "            Since this is a small dataset, please provide:\n",
    "            1. Detailed analysis of each record\n",
    "            2. Specific patterns and outliers\n",
    "            3. Actionable recommendations\n",
    "            4. Confidence level in findings\n",
    "            \"\"\"\n",
    "        \n",
    "        elif approach == 'statistical_summary':\n",
    "            # Large dataset - focus on statistics\n",
    "            stats_summary = df.describe().to_dict() if len(df.select_dtypes(include=['number']).columns) > 0 else {}\n",
    "            prompt = f\"\"\"\n",
    "            {base_context}\n",
    "            \n",
    "            Statistical Summary:\n",
    "            {json.dumps(stats_summary, indent=2, default=str)}\n",
    "            \n",
    "            Question: {question}\n",
    "            \n",
    "            For this large dataset, focus on:\n",
    "            1. High-level trends and patterns\n",
    "            2. Statistical significance of findings\n",
    "            3. Strategic implications\n",
    "            4. Areas needing deeper investigation\n",
    "            \"\"\"\n",
    "        \n",
    "        elif approach == 'time_series_analysis':\n",
    "            # Time-based data\n",
    "            date_columns = [col for col in df.columns if df[col].dtype == 'datetime64[ns]']\n",
    "            prompt = f\"\"\"\n",
    "            {base_context}\n",
    "            \n",
    "            Time Series Data with date columns: {date_columns}\n",
    "            Sample: {df.head(5).to_dict('records')}\n",
    "            \n",
    "            Question: {question}\n",
    "            \n",
    "            For this time series data, analyze:\n",
    "            1. Temporal trends and seasonality\n",
    "            2. Growth rates and momentum\n",
    "            3. Forecast implications\n",
    "            4. Time-based recommendations\n",
    "            \"\"\"\n",
    "        \n",
    "        else:\n",
    "            # Balanced approach\n",
    "            prompt = f\"\"\"\n",
    "            {base_context}\n",
    "            \n",
    "            Representative Sample:\n",
    "            {df.head(5).to_dict('records')}\n",
    "            \n",
    "            Question: {question}\n",
    "            \n",
    "            Please provide balanced analysis covering:\n",
    "            1. Key insights and patterns\n",
    "            2. Business implications\n",
    "            3. Actionable recommendations\n",
    "            4. Next steps for investigation\n",
    "            \"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def adaptive_analysis(self, df, question, analysis_goal='general'):\n",
    "        \"\"\"Run adaptive analysis with optimized prompting\"\"\"\n",
    "        \n",
    "        optimized_prompt = self.generate_adaptive_prompt(df, question, analysis_goal)\n",
    "        \n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert data analyst who adapts analysis depth to data characteristics.\"},\n",
    "                    {\"role\": \"user\", \"content\": optimized_prompt}\n",
    "                ],\n",
    "                max_tokens=700,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "        \n",
    "        except Exception as e:\n",
    "            return f\"Adaptive analysis error: {e}\"\n",
    "\n",
    "# Test adaptive prompting\n",
    "adaptive_engine = AdaptivePromptEngine()\n",
    "\n",
    "# This will automatically choose the best approach for your data\n",
    "adaptive_results = adaptive_engine.adaptive_analysis(\n",
    "    sales_data, \n",
    "    \"What strategies should we pursue to maximize revenue growth?\",\n",
    "    analysis_goal='strategic_planning'\n",
    ")\n",
    "\n",
    "print(\"Adaptive Analysis Results:\")\n",
    "print(adaptive_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
